[11/02 12:45:10] detectron2 INFO: Rank of current process: 0. World size: 1
[11/02 12:45:11] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
cv2                       4.2.0
------------------------  -------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/02 12:45:11] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/02 12:45:11] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/02 12:45:11] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/02 12:45:11] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/02 12:45:11] d2.utils.env INFO: Using a generated random seed 12975389
[11/02 13:18:16] detectron2 INFO: Rank of current process: 0. World size: 1
[11/02 13:18:17] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/02 13:18:17] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/02 13:18:17] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/02 13:18:17] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/02 13:18:18] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/02 13:18:18] d2.utils.env INFO: Using a generated random seed 18477991
[11/02 13:28:02] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/02 13:28:04] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/02 13:28:04] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/02 13:28:04] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/02 13:28:04] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/02 13:28:04] d2.data.build INFO: Using training sampler TrainingSampler
[11/02 13:28:05] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/02 13:28:05] d2.engine.train_loop INFO: Starting training from iteration 0
[11/02 13:28:06] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 46, in __call__
    radar_intensity = utils.read_image(radar_intensity_name, format='L')
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/detection_utils.py", line 48, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 1062, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 653, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'data/RobotCar/object/radar/1547122315407487.jpg'

[11/02 13:28:06] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/03 08:19:00] detectron2 INFO: Rank of current process: 0. World size: 1
[11/03 08:19:02] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/03 08:19:02] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/03 08:19:02] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/03 08:19:02] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/03 08:19:02] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/03 08:19:02] d2.utils.env INFO: Using a generated random seed 3278491
[11/03 08:19:17] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/03 08:19:20] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/03 08:19:20] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/03 08:19:20] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/03 08:19:20] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/03 08:19:20] d2.data.build INFO: Using training sampler TrainingSampler
[11/03 08:19:21] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/03 08:19:21] d2.engine.train_loop INFO: Starting training from iteration 0
[11/03 08:19:21] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 46, in __call__
    radar_intensity = utils.read_image(radar_intensity_name, format='L')
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/detection_utils.py", line 48, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 1062, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 653, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'data/RobotCar/object/radar/1547122754400863.jpg'

[11/03 08:19:21] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/04 10:37:40] detectron2 INFO: Rank of current process: 0. World size: 1
[11/04 10:37:42] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
cv2                       4.2.0
------------------------  -------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/04 10:37:42] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/04 10:37:42] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/04 10:37:42] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/04 10:37:42] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/04 10:37:42] d2.utils.env INFO: Using a generated random seed 42588585
[11/04 10:40:06] detectron2 INFO: Rank of current process: 0. World size: 1
[11/04 10:40:07] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/04 10:40:07] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/04 10:40:07] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/04 10:40:07] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/04 10:40:07] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/04 10:40:07] d2.utils.env INFO: Using a generated random seed 8101875
[11/04 10:40:23] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/04 10:40:26] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/04 10:40:26] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/04 10:40:26] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/04 10:40:26] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/04 10:40:26] d2.data.build INFO: Using training sampler TrainingSampler
[11/04 10:40:27] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/04 10:40:27] d2.engine.train_loop INFO: Starting training from iteration 0
[11/04 10:40:27] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 46, in __call__
    radar_intensity = utils.read_image(radar_intensity_name, format='L')
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/detection_utils.py", line 48, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 1062, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 653, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'data/RobotCar/object/radar/1547120868675891.jpg'

[11/04 10:40:27] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/06 10:32:28] detectron2 INFO: Rank of current process: 0. World size: 1
[11/06 10:32:30] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
cv2                       4.2.0
------------------------  -------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/06 10:32:30] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/06 10:32:30] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/06 10:32:30] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/06 10:32:30] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/06 10:32:30] d2.utils.env INFO: Using a generated random seed 30892817
[11/06 10:34:41] detectron2 INFO: Rank of current process: 0. World size: 1
[11/06 10:34:42] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/06 10:34:42] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/06 10:34:42] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/06 10:34:42] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/06 10:34:42] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/06 10:34:42] d2.utils.env INFO: Using a generated random seed 43010158
[11/06 10:34:57] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/06 10:35:00] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/06 10:35:00] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/06 10:35:00] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/06 10:35:00] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/06 10:35:00] d2.data.build INFO: Using training sampler TrainingSampler
[11/06 10:35:01] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/06 10:35:01] d2.engine.train_loop INFO: Starting training from iteration 0
[11/06 10:35:01] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 46, in __call__
    radar_intensity = utils.read_image(radar_intensity_name, format='L')
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/detection_utils.py", line 48, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 1062, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 653, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'data/RobotCar/object/radar/1547120804903500.jpg'

[11/06 10:35:01] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/06 11:04:53] detectron2 INFO: Rank of current process: 0. World size: 1
[11/06 11:04:55] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/06 11:04:55] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/06 11:04:55] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/06 11:04:55] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/06 11:04:55] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/06 11:04:55] d2.utils.env INFO: Using a generated random seed 55807310
[11/06 11:05:10] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/06 11:05:13] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/06 11:05:14] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/06 11:05:14] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/06 11:05:14] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/06 11:05:14] d2.data.build INFO: Using training sampler TrainingSampler
[11/06 11:05:15] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/06 11:05:15] d2.engine.train_loop INFO: Starting training from iteration 0
[11/06 11:05:15] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 46, in __call__
    radar_intensity = utils.read_image(radar_intensity_name, format='L')
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/detection_utils.py", line 48, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 1062, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 653, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'data/RobotCar/object/radar/1547122807360707.jpg'

[11/06 11:05:15] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/06 16:39:15] detectron2 INFO: Rank of current process: 0. World size: 1
[11/06 16:39:17] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/06 16:39:17] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/06 16:39:17] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/06 16:39:17] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/06 16:39:17] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/06 16:39:17] d2.utils.env INFO: Using a generated random seed 18349016
[11/06 16:39:33] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/06 16:39:35] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/06 16:39:35] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/06 16:39:35] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/06 16:39:35] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/06 16:39:35] d2.data.build INFO: Using training sampler TrainingSampler
[11/06 16:39:36] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/06 16:39:36] d2.engine.train_loop INFO: Starting training from iteration 0
[11/06 16:39:37] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 46, in __call__
    radar_intensity = utils.read_image(radar_intensity_name, format='L')
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/detection_utils.py", line 48, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 1062, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 653, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'data/RobotCar/object/radar/1547122253664508.jpg'

[11/06 16:39:37] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/17 16:54:46] detectron2 INFO: Rank of current process: 0. World size: 1
[11/17 16:54:48] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/17 16:54:48] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/17 16:54:48] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/17 16:54:48] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/17 16:54:48] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/17 16:54:48] d2.utils.env INFO: Using a generated random seed 49307585
[11/17 16:55:03] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/17 16:55:06] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/17 16:55:06] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/17 16:55:06] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/17 16:55:06] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/17 16:55:06] d2.data.build INFO: Using training sampler TrainingSampler
[11/17 16:55:07] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/17 16:55:07] d2.engine.train_loop INFO: Starting training from iteration 0
[11/17 16:55:07] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 46, in __call__
    radar_intensity = utils.read_image(radar_intensity_name, format='L')
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/detection_utils.py", line 48, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 1062, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 653, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'data/RobotCar/object/radar/1547122462958457.jpg'

[11/17 16:55:07] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/22 15:37:57] detectron2 INFO: Rank of current process: 0. World size: 1
[11/22 15:37:59] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/22 15:37:59] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/22 15:37:59] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/22 15:37:59] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/22 15:37:59] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/22 15:37:59] d2.utils.env INFO: Using a generated random seed 59730144
[11/22 15:38:13] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/22 15:38:15] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/22 15:38:16] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/22 15:38:16] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/22 15:38:16] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/22 15:38:16] d2.data.build INFO: Using training sampler TrainingSampler
[11/22 15:38:17] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/22 15:38:17] d2.engine.train_loop INFO: Starting training from iteration 0
[11/22 15:38:18] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 38, in forward
    features = self.backbone(radar_data.tensor, lidar_data.tensor)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 195, in forward
    radar_features = self.radar_backbone(radar_data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 148, in forward
    x_j = downsampler(x_j)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/layers/wrappers.py", line 95, in forward
    x = self.norm(x)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED
[11/22 15:38:18] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/22 15:45:26] detectron2 INFO: Rank of current process: 0. World size: 1
[11/22 15:45:27] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/22 15:45:27] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/22 15:45:27] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/22 15:45:27] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/22 15:45:27] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/22 15:45:27] d2.utils.env INFO: Using a generated random seed 27729343
[11/22 15:45:29] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/22 15:45:31] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/22 15:45:32] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/22 15:45:32] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/22 15:45:32] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/22 15:45:32] d2.data.build INFO: Using training sampler TrainingSampler
[11/22 15:45:32] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/22 15:45:32] d2.engine.train_loop INFO: Starting training from iteration 0
[11/22 15:45:33] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 38, in forward
    features = self.backbone(radar_data.tensor, lidar_data.tensor)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 195, in forward
    radar_features = self.radar_backbone(radar_data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 148, in forward
    x_j = downsampler(x_j)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/layers/wrappers.py", line 95, in forward
    x = self.norm(x)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED
[11/22 15:45:33] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/22 15:59:39] detectron2 INFO: Rank of current process: 0. World size: 1
[11/22 15:59:40] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/22 15:59:40] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/22 15:59:40] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/22 15:59:40] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/22 15:59:40] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/22 15:59:40] d2.utils.env INFO: Using a generated random seed 41362477
[11/22 15:59:54] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/22 15:59:57] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/22 15:59:57] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/22 15:59:57] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/22 15:59:57] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/22 15:59:57] d2.data.build INFO: Using training sampler TrainingSampler
[11/22 15:59:57] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/22 15:59:57] d2.engine.train_loop INFO: Starting training from iteration 0
[11/22 16:00:00] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 38, in forward
    features = self.backbone(radar_data.tensor, lidar_data.tensor)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 195, in forward
    radar_features = self.radar_backbone(radar_data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 148, in forward
    x_j = downsampler(x_j)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/layers/wrappers.py", line 95, in forward
    x = self.norm(x)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED
[11/22 16:00:00] d2.engine.hooks INFO: Total training time: 0:00:02 (0:00:00 on hooks)
[11/24 02:21:03] detectron2 INFO: Rank of current process: 0. World size: 1
[11/24 02:21:03] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.7.7 (default, May  7 2020, 21:25:33) [GCC 7.3.0]
numpy                     1.18.1
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 7.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.1 @/opt/conda/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    7.1.2
torchvision               0.6.0a0+35d732a @/opt/conda/lib/python3.7/site-packages/torchvision
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/24 02:21:03] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/24 02:21:03] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/24 02:21:03] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/24 02:21:03] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/24 02:21:03] d2.utils.env INFO: Using a generated random seed 3819400
[11/25 15:41:30] detectron2 INFO: Rank of current process: 0. World size: 1
[11/25 15:41:30] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.7.7 (default, May  7 2020, 21:25:33) [GCC 7.3.0]
numpy                     1.18.1
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 7.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.1 @/opt/conda/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    7.1.2
torchvision               0.6.0a0+35d732a @/opt/conda/lib/python3.7/site-packages/torchvision
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/25 15:41:30] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/25 15:41:30] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/25 15:41:30] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/25 15:41:30] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/25 15:41:30] d2.utils.env INFO: Using a generated random seed 31120380
[11/25 15:56:27] detectron2 INFO: Rank of current process: 0. World size: 1
[11/25 15:56:27] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.7 (default, May  7 2020, 21:25:33) [GCC 7.3.0]
numpy                     1.18.1
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 7.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.1 @/opt/conda/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    7.1.2
torchvision               0.6.0a0+35d732a @/opt/conda/lib/python3.7/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/25 15:56:27] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/25 15:56:27] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/25 15:56:27] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/25 15:56:27] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/25 15:56:27] d2.utils.env INFO: Using a generated random seed 28400058
[11/25 16:10:02] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/25 16:10:06] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/25 16:10:06] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/25 16:10:06] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/25 16:10:06] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/25 16:10:06] d2.data.build INFO: Using training sampler TrainingSampler
[11/25 16:10:07] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/25 16:10:07] d2.engine.train_loop INFO: Starting training from iteration 0
[11/25 16:12:49] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 38, in forward
    features = self.backbone(radar_data.tensor, lidar_data.tensor)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 195, in forward
    radar_features = self.radar_backbone(radar_data)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 148, in forward
    x_j = downsampler(x_j)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/detectron2/detectron2/layers/wrappers.py", line 95, in forward
    x = self.norm(x)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED
[11/25 16:12:49] d2.engine.hooks INFO: Total training time: 0:02:41 (0:00:00 on hooks)
[11/26 17:24:35] detectron2 INFO: Rank of current process: 0. World size: 1
[11/26 17:24:36] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.7.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.2.0
torchvision               0.8.2 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torchvision
cv2                       4.6.0
------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.2-Product Build 20240823 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/26 17:24:36] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/26 17:24:36] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/26 17:24:36] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/26 17:24:36] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/26 17:24:36] d2.utils.env INFO: Using a generated random seed 37201137
[11/26 17:25:44] detectron2 INFO: Rank of current process: 0. World size: 1
[11/26 17:25:45] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.7.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/10.2.89
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    9.2.0
torchvision               0.8.2 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.6.0
------------------------  -----------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.2-Product Build 20240823 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/26 17:25:45] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/26 17:25:45] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/26 17:25:45] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/26 17:25:45] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/26 17:25:45] d2.utils.env INFO: Using a generated random seed 46056757
[11/26 17:25:54] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/26 17:25:57] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/26 17:25:57] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/26 17:25:57] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/26 17:25:57] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/26 17:25:57] d2.data.build INFO: Using training sampler TrainingSampler
[11/26 17:25:58] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/26 17:25:58] d2.engine.train_loop INFO: Starting training from iteration 0
[11/26 17:26:00] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 32, in forward
    radar_data, lidar_data = self.preprocess_image(batched_inputs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in preprocess_image
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in <listcomp>
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
RuntimeError: CUDA error: no kernel image is available for execution on the device
[11/26 17:26:00] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/26 17:56:24] detectron2 INFO: Rank of current process: 0. World size: 1
[11/26 17:56:26] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.7.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.2.0
torchvision               0.8.2 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torchvision
cv2                       4.6.0
------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.2-Product Build 20240823 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/26 17:56:26] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/26 17:56:26] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/26 17:56:26] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/26 17:56:26] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/26 17:56:26] d2.utils.env INFO: Using a generated random seed 26531846
[11/26 17:57:05] detectron2 INFO: Rank of current process: 0. World size: 1
[11/26 17:57:06] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.7.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/10.2.89
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    9.2.0
torchvision               0.8.2 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.6.0
------------------------  -----------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.2-Product Build 20240823 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/26 17:57:06] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/26 17:57:06] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/26 17:57:06] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/26 17:57:06] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/26 17:57:06] d2.utils.env INFO: Using a generated random seed 7571174
[11/26 17:57:15] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/26 17:57:17] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/26 17:57:18] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/26 17:57:18] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/26 17:57:18] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/26 17:57:18] d2.data.build INFO: Using training sampler TrainingSampler
[11/26 17:57:19] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/26 17:57:19] d2.engine.train_loop INFO: Starting training from iteration 0
[11/26 17:57:20] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 32, in forward
    radar_data, lidar_data = self.preprocess_image(batched_inputs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in preprocess_image
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in <listcomp>
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
RuntimeError: CUDA error: no kernel image is available for execution on the device
[11/26 17:57:20] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/26 18:02:50] detectron2 INFO: Rank of current process: 0. World size: 1
[11/26 18:02:51] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.7.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/10.2.89
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    9.2.0
torchvision               0.8.2 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.6.0
------------------------  -----------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.2-Product Build 20240823 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/26 18:02:51] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/26 18:02:51] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/26 18:02:51] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/26 18:02:51] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/26 18:02:51] d2.utils.env INFO: Using a generated random seed 52022972
[11/26 18:02:51] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/26 18:02:53] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/26 18:02:54] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/26 18:02:54] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/26 18:02:54] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/26 18:02:54] d2.data.build INFO: Using training sampler TrainingSampler
[11/26 18:02:54] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/26 18:02:54] d2.engine.train_loop INFO: Starting training from iteration 0
[11/26 18:02:55] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 32, in forward
    radar_data, lidar_data = self.preprocess_image(batched_inputs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in preprocess_image
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in <listcomp>
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
RuntimeError: CUDA error: no kernel image is available for execution on the device
[11/26 18:02:55] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/27 20:45:19] detectron2 INFO: Rank of current process: 0. World size: 1
[11/27 20:45:20] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.5 (default, Dec  9 2021, 17:04:37) [GCC 8.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/usr/local/lib/python3.7/dist-packages/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /usr/local/lib/python3.7/dist-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.7.1 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/10.2.89
Pillow                    9.5.0
torchvision               0.8.2 @/usr/local/lib/python3.7/dist-packages/torchvision
torchvision arch flags    /usr/local/lib/python3.7/dist-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  -----------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/27 20:45:20] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/27 20:45:20] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/27 20:45:20] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/27 20:45:20] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/27 20:45:20] d2.utils.env INFO: Using a generated random seed 20735539
[11/27 20:45:29] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/27 20:45:32] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/27 20:45:32] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/27 20:45:32] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/27 20:45:32] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/27 20:45:32] d2.data.build INFO: Using training sampler TrainingSampler
[11/27 20:45:33] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/27 20:45:33] d2.engine.train_loop INFO: Starting training from iteration 0
[11/27 20:45:35] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/usr/local/lib/python3.7/dist-packages/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 32, in forward
    radar_data, lidar_data = self.preprocess_image(batched_inputs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in preprocess_image
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in <listcomp>
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
RuntimeError: CUDA error: no kernel image is available for execution on the device
[11/27 20:45:35] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/28 15:33:08] detectron2 INFO: Rank of current process: 0. World size: 1
[11/28 15:33:09] detectron2 INFO: Environment info:
------------------------  ------------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/opt/conda/lib/python3.10/site-packages/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[11/28 15:33:09] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[11/28 15:33:09] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/28 15:33:09] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/28 15:33:09] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/28 15:33:09] d2.utils.env INFO: Using a generated random seed 10040964
[11/28 15:34:11] detectron2 INFO: Rank of current process: 0. World size: 1
[11/28 15:34:11] detectron2 INFO: Environment info:
------------------------  ------------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/opt/conda/lib/python3.10/site-packages/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[11/28 15:34:11] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[11/28 15:34:11] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/28 15:34:11] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/28 15:34:11] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/28 15:34:11] d2.utils.env INFO: Using a generated random seed 12101145
[11/28 15:35:33] detectron2 INFO: Rank of current process: 0. World size: 1
[11/28 15:35:33] detectron2 INFO: Environment info:
------------------------  ------------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/opt/conda/lib/python3.10/site-packages/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[11/28 15:35:33] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[11/28 15:35:33] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/28 15:35:33] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/28 15:35:33] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/28 15:35:33] d2.utils.env INFO: Using a generated random seed 34304592
[12/02 09:46:26] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 09:46:26] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
------------------------  -----------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 09:46:26] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 09:46:26] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 09:46:26] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 09:46:26] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 09:46:26] d2.utils.env INFO: Using a generated random seed 27237983
[12/02 09:58:22] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 09:58:22] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
------------------------  -----------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 09:58:22] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 09:58:22] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 09:58:22] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 09:58:22] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 09:58:22] d2.utils.env INFO: Using a generated random seed 23162567
[12/02 09:59:25] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 09:59:26] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
------------------------  -----------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 09:59:26] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 09:59:26] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 09:59:26] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 09:59:26] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 09:59:26] d2.utils.env INFO: Using a generated random seed 26252702
[12/02 10:01:05] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 10:01:05] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
------------------------  -----------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 10:01:05] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 10:01:05] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 10:01:05] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 10:01:05] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 10:01:05] d2.utils.env INFO: Using a generated random seed 6073420
[12/02 10:03:53] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 10:03:54] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 10:03:54] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 10:03:54] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 10:03:54] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 10:03:54] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 10:03:54] d2.utils.env INFO: Using a generated random seed 54244387
[12/02 10:43:24] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 10:43:25] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/MVDNet/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
------------------------  -----------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 10:43:25] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 10:43:25] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 10:43:25] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 10:43:25] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 10:43:25] d2.utils.env INFO: Using a generated random seed 25514528
[12/02 11:57:22] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 11:57:23] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/MVDNet/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
------------------------  -----------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 11:57:23] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 11:57:23] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 11:57:23] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 11:57:23] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 11:57:23] d2.utils.env INFO: Using a generated random seed 23515178
[12/02 12:22:08] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 12:22:09] detectron2 INFO: Environment info:
------------------------  ----------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/MVDNet/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/MVDNet/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 12:22:09] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 12:22:09] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 12:22:09] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 12:22:09] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 12:22:09] d2.utils.env INFO: Using a generated random seed 9339795
[12/02 12:22:09] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/02 12:22:11] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/02 12:22:12] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[12/02 12:22:12] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/02 12:22:12] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/02 12:22:12] d2.data.build INFO: Using training sampler TrainingSampler
[12/02 12:22:12] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/02 12:22:12] d2.engine.train_loop INFO: Starting training from iteration 0
[12/02 12:22:13] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/MVDNet/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/MVDNet/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/jmz9sad/MVDNet/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/opt/conda/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
AttributeError: Caught AttributeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/MVDNet/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/jmz9sad/MVDNet/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 81, in __call__
    lidar_intensity, lidar_occupancy = lidar_pc2pixor(
  File "/home/jmz9sad/MVDNet/mvdnet/data/robotcar_utils.py", line 148, in lidar_pc2pixor
    pixel_h = np.int(np.round((h2 - h1) / delta_h))
  File "/opt/conda/lib/python3.10/site-packages/numpy/__init__.py", line 324, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'int'.
`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations

[12/02 12:22:13] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/02 15:11:36] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 15:11:37] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ---------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 15:11:37] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 15:11:37] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 15:11:37] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 15:11:37] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 15:11:37] d2.utils.env INFO: Using a generated random seed 37868880
[12/02 15:11:37] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/02 15:11:40] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/02 15:11:40] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[12/02 15:11:40] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/02 15:11:40] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/02 15:11:40] d2.data.build INFO: Using training sampler TrainingSampler
[12/02 15:11:41] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/02 15:11:41] d2.engine.train_loop INFO: Starting training from iteration 0
[12/02 15:11:42] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/opt/conda/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
AttributeError: Caught AttributeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/jmz9sad/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 81, in __call__
    lidar_intensity, lidar_occupancy = lidar_pc2pixor(
  File "/home/jmz9sad/cs6501-wireless-project/mvdnet/data/robotcar_utils.py", line 148, in lidar_pc2pixor
    pixel_h = np.int(np.round((h2 - h1) / delta_h))
  File "/opt/conda/lib/python3.10/site-packages/numpy/__init__.py", line 324, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'int'.
`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations

[12/02 15:11:42] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/02 16:00:52] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 16:00:52] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ---------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 16:00:52] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 16:00:52] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 16:00:52] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 16:00:52] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 16:00:52] d2.utils.env INFO: Using a generated random seed 53283862
[12/02 16:00:53] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/02 16:00:55] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/02 16:00:55] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[12/02 16:00:55] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/02 16:00:56] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/02 16:00:56] d2.data.build INFO: Using training sampler TrainingSampler
[12/02 16:00:56] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/02 16:00:56] d2.engine.train_loop INFO: Starting training from iteration 0
[12/02 16:00:57] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/opt/conda/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
AttributeError: Caught AttributeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/jmz9sad/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 81, in __call__
    lidar_intensity, lidar_occupancy = lidar_pc2pixor(
  File "/home/jmz9sad/cs6501-wireless-project/mvdnet/data/robotcar_utils.py", line 148, in lidar_pc2pixor
    pixel_h = np.int(np.round((h2 - h1) / delta_h))
  File "/opt/conda/lib/python3.10/site-packages/numpy/__init__.py", line 324, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'int'.
`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations

[12/02 16:00:57] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/03 08:51:49] detectron2 INFO: Rank of current process: 0. World size: 1
[12/03 08:51:50] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ---------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/03 08:51:50] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/03 08:51:50] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/03 08:51:50] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/03 08:51:50] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/03 08:51:50] d2.utils.env INFO: Using a generated random seed 50994618
[12/03 08:51:50] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/03 08:51:53] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/03 08:51:53] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[12/03 08:51:53] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/03 08:51:53] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/03 08:51:53] d2.data.build INFO: Using training sampler TrainingSampler
[12/03 08:51:54] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/03 08:51:54] d2.engine.train_loop INFO: Starting training from iteration 0
[12/03 08:51:59] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jmz9sad/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 41, in forward
    proposals, proposal_losses = self.proposal_generator(radar_data, features, gt_instances)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jmz9sad/cs6501-wireless-project/mvdnet/modeling/proposal_generator/mvdnet_rrpn.py", line 180, in forward
    for loss_key, loss_val in outputs[f].losses().items():
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rpn_outputs.py", line 327, in losses
    gt_objectness_logits, gt_anchor_deltas = self._get_ground_truth()
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rrpn_outputs.py", line 222, in _get_ground_truth
    match_quality_matrix = pairwise_iou_rotated(gt_boxes_i, anchors_i)
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/structures/rotated_boxes.py", line 498, in pairwise_iou
    return pairwise_iou_rotated(boxes1.tensor, boxes2.tensor)
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/layers/rotated_boxes.py", line 23, in pairwise_iou_rotated
    return _C.box_iou_rotated(boxes1, boxes2)
RuntimeError: Not compiled with GPU support
[12/03 08:51:59] d2.engine.hooks INFO: Total training time: 0:00:05 (0:00:00 on hooks)
[12/03 09:00:36] detectron2 INFO: Rank of current process: 0. World size: 1
[12/03 09:00:36] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ---------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/03 09:00:36] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/03 09:00:36] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/03 09:00:36] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/03 09:00:36] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/03 09:00:36] d2.utils.env INFO: Using a generated random seed 37516039
[12/03 09:00:37] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/03 09:00:39] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/03 09:00:39] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[12/03 09:00:39] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/03 09:00:39] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/03 09:00:39] d2.data.build INFO: Using training sampler TrainingSampler
[12/03 09:00:40] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/03 09:00:40] d2.engine.train_loop INFO: Starting training from iteration 0
[12/03 09:00:43] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jmz9sad/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 41, in forward
    proposals, proposal_losses = self.proposal_generator(radar_data, features, gt_instances)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jmz9sad/cs6501-wireless-project/mvdnet/modeling/proposal_generator/mvdnet_rrpn.py", line 180, in forward
    for loss_key, loss_val in outputs[f].losses().items():
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rpn_outputs.py", line 327, in losses
    gt_objectness_logits, gt_anchor_deltas = self._get_ground_truth()
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rrpn_outputs.py", line 222, in _get_ground_truth
    match_quality_matrix = pairwise_iou_rotated(gt_boxes_i, anchors_i)
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/structures/rotated_boxes.py", line 498, in pairwise_iou
    return pairwise_iou_rotated(boxes1.tensor, boxes2.tensor)
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/layers/rotated_boxes.py", line 23, in pairwise_iou_rotated
    return _C.box_iou_rotated(boxes1, boxes2)
RuntimeError: Not compiled with GPU support
[12/03 09:00:43] d2.engine.hooks INFO: Total training time: 0:00:03 (0:00:00 on hooks)
[12/03 09:07:42] detectron2 INFO: Rank of current process: 0. World size: 1
[12/03 09:07:43] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ---------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/03 09:07:43] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/03 09:07:43] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/03 09:07:43] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/03 09:07:43] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/03 09:07:43] d2.utils.env INFO: Using a generated random seed 43749515
[12/03 09:07:43] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/03 09:07:45] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/03 09:07:45] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[12/03 09:07:45] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/03 09:07:46] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/03 09:07:46] d2.data.build INFO: Using training sampler TrainingSampler
[12/03 09:07:46] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/03 09:07:46] d2.engine.train_loop INFO: Starting training from iteration 0
[12/03 09:07:49] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jmz9sad/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 41, in forward
    proposals, proposal_losses = self.proposal_generator(radar_data, features, gt_instances)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jmz9sad/cs6501-wireless-project/mvdnet/modeling/proposal_generator/mvdnet_rrpn.py", line 180, in forward
    for loss_key, loss_val in outputs[f].losses().items():
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rpn_outputs.py", line 327, in losses
    gt_objectness_logits, gt_anchor_deltas = self._get_ground_truth()
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rrpn_outputs.py", line 222, in _get_ground_truth
    match_quality_matrix = pairwise_iou_rotated(gt_boxes_i, anchors_i)
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/structures/rotated_boxes.py", line 498, in pairwise_iou
    return pairwise_iou_rotated(boxes1.tensor, boxes2.tensor)
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/layers/rotated_boxes.py", line 23, in pairwise_iou_rotated
    return _C.box_iou_rotated(boxes1, boxes2)
RuntimeError: Not compiled with GPU support
[12/03 09:07:49] d2.engine.hooks INFO: Total training time: 0:00:03 (0:00:00 on hooks)
[12/03 09:11:43] detectron2 INFO: Rank of current process: 0. World size: 1
[12/03 09:11:44] detectron2 INFO: Environment info:
------------------------  ------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
------------------------  ------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/03 09:11:44] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/03 09:11:44] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/03 09:11:44] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/03 09:11:44] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/03 09:11:44] d2.utils.env INFO: Using a generated random seed 44833605
[12/03 09:13:43] detectron2 INFO: Rank of current process: 0. World size: 1
[12/03 09:13:43] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ---------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/03 09:13:43] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/03 09:13:43] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/03 09:13:43] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/03 09:13:43] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/03 09:13:43] d2.utils.env INFO: Using a generated random seed 44406802
[12/03 09:13:44] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/03 09:13:46] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/03 09:13:46] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[12/03 09:13:46] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/03 09:13:46] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/03 09:13:46] d2.data.build INFO: Using training sampler TrainingSampler
[12/03 09:13:46] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/03 09:13:46] d2.engine.train_loop INFO: Starting training from iteration 0
[12/03 09:13:49] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jmz9sad/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 41, in forward
    proposals, proposal_losses = self.proposal_generator(radar_data, features, gt_instances)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jmz9sad/cs6501-wireless-project/mvdnet/modeling/proposal_generator/mvdnet_rrpn.py", line 180, in forward
    for loss_key, loss_val in outputs[f].losses().items():
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rpn_outputs.py", line 327, in losses
    gt_objectness_logits, gt_anchor_deltas = self._get_ground_truth()
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rrpn_outputs.py", line 222, in _get_ground_truth
    match_quality_matrix = pairwise_iou_rotated(gt_boxes_i, anchors_i)
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/structures/rotated_boxes.py", line 498, in pairwise_iou
    return pairwise_iou_rotated(boxes1.tensor, boxes2.tensor)
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/layers/rotated_boxes.py", line 23, in pairwise_iou_rotated
    return _C.box_iou_rotated(boxes1, boxes2)
RuntimeError: Not compiled with GPU support
[12/03 09:13:49] d2.engine.hooks INFO: Total training time: 0:00:03 (0:00:00 on hooks)
[12/03 09:16:20] detectron2 INFO: Rank of current process: 0. World size: 1
[12/03 09:16:20] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.5.1+cu118 @/home/jmz9sad/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.20.1+cu118 @/home/jmz9sad/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/jmz9sad/.local/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ---------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.5.3 (Git Hash 66f0cb9eb66affd2da3bf5f8d897376f04aae6af)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DLIBKINETO_NOXPUPTI=ON -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, TORCH_VERSION=2.5.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/03 09:16:20] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/03 09:16:20] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/03 09:16:20] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/03 09:16:20] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/03 09:16:20] d2.utils.env INFO: Using a generated random seed 21151581
[12/03 09:16:20] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/03 09:16:23] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/03 09:16:23] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[12/03 09:16:23] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/03 09:16:23] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/03 09:16:23] d2.data.build INFO: Using training sampler TrainingSampler
[12/03 09:16:23] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/03 09:16:23] d2.engine.train_loop INFO: Starting training from iteration 0
[12/03 09:16:25] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/jmz9sad/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jmz9sad/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jmz9sad/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 41, in forward
    proposals, proposal_losses = self.proposal_generator(radar_data, features, gt_instances)
  File "/home/jmz9sad/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/jmz9sad/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/jmz9sad/cs6501-wireless-project/mvdnet/modeling/proposal_generator/mvdnet_rrpn.py", line 180, in forward
    for loss_key, loss_val in outputs[f].losses().items():
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rpn_outputs.py", line 327, in losses
    gt_objectness_logits, gt_anchor_deltas = self._get_ground_truth()
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rrpn_outputs.py", line 222, in _get_ground_truth
    match_quality_matrix = pairwise_iou_rotated(gt_boxes_i, anchors_i)
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/structures/rotated_boxes.py", line 498, in pairwise_iou
    return pairwise_iou_rotated(boxes1.tensor, boxes2.tensor)
  File "/home/jmz9sad/cs6501-wireless-project/detectron2/detectron2/layers/rotated_boxes.py", line 23, in pairwise_iou_rotated
    return _C.box_iou_rotated(boxes1, boxes2)
RuntimeError: Not compiled with GPU support
[12/03 09:16:25] d2.engine.hooks INFO: Total training time: 0:00:02 (0:00:00 on hooks)
[12/15 16:05:09] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:05:09] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:05:09] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:05:09] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:05:09] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:05:09] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:05:09] d2.utils.env INFO: Using a generated random seed 9657469
[12/15 16:05:09] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:05:10] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:05:10] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:05:10] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:05:10] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:05:10] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:05:10] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:05:10] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:05:11] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547121730359931_1.bin'

[12/15 16:05:11] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:09:11] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:09:11] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:09:11] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:09:11] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:09:11] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:09:11] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:09:11] d2.utils.env INFO: Using a generated random seed 11662753
[12/15 16:09:11] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:09:12] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:09:12] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:09:12] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:09:12] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:09:12] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:09:12] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:09:12] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:09:12] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547122877161653_1.bin'

[12/15 16:09:12] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:10:43] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:10:43] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:10:43] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:10:43] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:10:43] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:10:43] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:10:43] d2.utils.env INFO: Using a generated random seed 43604887
[12/15 16:10:43] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:10:43] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:10:44] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:10:44] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:10:44] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:10:44] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:10:44] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:10:44] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:10:44] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547121707368567_1.bin'

[12/15 16:10:44] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:11:21] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:11:22] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:11:22] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:11:22] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:11:22] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:11:22] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:11:22] d2.utils.env INFO: Using a generated random seed 22359648
[12/15 16:11:22] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:11:22] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:11:22] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:11:22] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:11:22] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:11:22] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:11:22] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:11:22] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:11:23] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547121444906931_1.bin'

[12/15 16:11:23] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:11:53] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:11:54] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:11:54] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:11:54] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:11:54] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:11:54] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:11:54] d2.utils.env INFO: Using a generated random seed 54111602
[12/15 16:11:54] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:11:54] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:11:54] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:11:54] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:11:54] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:11:54] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:11:54] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:11:54] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:11:54] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547121164265977_1.bin'

[12/15 16:11:54] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:12:19] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:12:20] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:12:20] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:12:20] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:12:20] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:12:20] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:12:20] d2.utils.env INFO: Using a generated random seed 20391012
[12/15 16:12:20] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:12:20] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:12:20] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:12:20] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:12:20] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:12:20] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:12:21] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:12:21] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:12:21] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547122521209540_1.bin'

[12/15 16:12:21] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:12:42] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:12:42] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:12:42] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:12:42] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:12:42] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:12:42] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:12:42] d2.utils.env INFO: Using a generated random seed 42897265
[12/15 16:12:42] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:12:43] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:12:43] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:12:43] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:12:43] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:12:43] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:12:43] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:12:43] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:12:43] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547121159270634_1.bin'

[12/15 16:12:43] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:13:37] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:13:38] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:13:38] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:13:38] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:13:38] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:13:38] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:13:38] d2.utils.env INFO: Using a generated random seed 38345109
[12/15 16:13:38] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:13:38] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:13:38] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:13:38] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:13:38] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:13:38] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:13:39] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:13:39] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:13:39] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547122761635413_1.bin'

[12/15 16:13:39] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:14:03] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:14:03] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:14:03] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:14:03] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:14:03] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:14:03] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:14:03] d2.utils.env INFO: Using a generated random seed 3590526
[12/15 16:14:03] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:14:03] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:14:04] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:14:04] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:14:04] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:14:04] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:14:04] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:14:04] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:14:04] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547121090978628_1.bin'

[12/15 16:14:04] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:14:29] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:14:29] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:14:29] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:14:29] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:14:29] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:14:29] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:14:29] d2.utils.env INFO: Using a generated random seed 29737789
[12/15 16:14:29] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:14:30] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:14:30] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:14:30] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:14:30] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:14:30] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:14:30] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:14:30] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:14:30] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547122219666543_1.bin'

[12/15 16:14:30] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:16:19] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:16:19] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:16:19] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:16:19] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:16:19] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:16:19] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:16:19] d2.utils.env INFO: Using a generated random seed 19693992
[12/15 16:16:19] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:16:20] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:16:20] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:16:20] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:16:20] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:16:20] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:16:20] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:16:20] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:16:20] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547121437410299_1.bin'

[12/15 16:16:20] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:30:00] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:30:01] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:30:01] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:30:01] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:30:01] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:30:01] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:30:01] d2.utils.env INFO: Using a generated random seed 1197333
[12/15 16:30:01] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:30:01] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:30:01] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:30:01] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:30:01] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:30:01] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:30:01] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:30:01] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:30:02] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547122890141613_1.bin'

[12/15 16:30:02] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:30:46] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:30:46] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:30:46] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:30:46] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:30:46] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:30:46] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:30:46] d2.utils.env INFO: Using a generated random seed 46849709
[12/15 16:30:46] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:30:47] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:30:47] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:30:47] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:30:47] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:30:47] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:30:47] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:30:47] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:30:47] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547120888169534_1.bin'

[12/15 16:30:47] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:34:32] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:34:33] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:34:33] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:34:33] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:34:33] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:34:33] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:34:33] d2.utils.env INFO: Using a generated random seed 33346808
[12/15 16:34:33] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:34:33] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:34:33] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:34:33] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:34:33] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:34:33] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:34:33] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:34:33] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:34:34] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547120984945419_1.bin'

[12/15 16:34:34] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:35:27] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:35:28] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:35:28] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:35:28] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:35:28] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:35:28] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:35:28] d2.utils.env INFO: Using a generated random seed 28255729
[12/15 16:35:28] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:35:28] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:35:28] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:35:28] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:35:28] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:35:28] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:35:28] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:35:28] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:35:29] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547121108994770_1.bin'

[12/15 16:35:29] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:36:11] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:36:12] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:36:12] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:36:12] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:36:12] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:36:12] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:36:12] d2.utils.env INFO: Using a generated random seed 12070126
[12/15 16:36:12] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:36:12] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:36:12] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:36:12] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:36:12] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:36:12] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:36:12] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:36:12] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:36:12] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547121784606122_1.bin'

[12/15 16:36:12] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:36:56] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:36:56] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:36:56] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:36:56] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:36:56] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:36:56] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:36:56] d2.utils.env INFO: Using a generated random seed 56614530
[12/15 16:36:56] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:36:57] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:36:57] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:36:57] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:36:57] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:36:57] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:36:57] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:36:57] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:36:57] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547122857904769_1.bin'

[12/15 16:36:57] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:37:23] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:37:23] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:37:23] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:37:23] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:37:23] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:37:23] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:37:23] d2.utils.env INFO: Using a generated random seed 23619578
[12/15 16:37:23] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:37:23] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:37:24] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:37:24] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:37:24] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:37:24] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:37:24] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:37:24] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:37:24] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547122425190434_1.bin'

[12/15 16:37:24] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:38:37] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:38:37] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:38:37] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:38:37] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:38:37] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:38:37] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:38:37] d2.utils.env INFO: Using a generated random seed 37667665
[12/15 16:38:37] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:38:38] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:38:38] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:38:38] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:38:38] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:38:38] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:38:38] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:38:38] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:38:38] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547121057452686_1.bin'

[12/15 16:38:38] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:39:02] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:39:03] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:39:03] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:39:03] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:39:03] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:39:03] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:39:03] d2.utils.env INFO: Using a generated random seed 3144692
[12/15 16:39:03] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:39:03] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:39:03] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:39:03] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:39:03] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:39:03] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:39:03] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:39:03] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:39:03] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547122871660161_1.bin'

[12/15 16:39:03] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:39:34] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:39:34] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:39:34] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:39:34] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:39:34] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:39:34] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:39:34] d2.utils.env INFO: Using a generated random seed 34921596
[12/15 16:39:35] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:39:35] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:39:35] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:39:35] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:39:35] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:39:35] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:39:35] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:39:35] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:39:35] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547121672642427_1.bin'

[12/15 16:39:35] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:41:39] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:41:39] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:41:39] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:41:39] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:41:39] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:41:39] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:41:39] d2.utils.env INFO: Using a generated random seed 39835189
[12/15 16:41:39] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:41:40] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:41:40] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:41:40] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:41:40] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:41:40] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:41:40] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:41:40] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:41:40] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547122773617482_1.bin'

[12/15 16:41:40] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:43:05] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:43:05] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:43:05] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:43:05] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:43:05] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:43:05] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:43:05] d2.utils.env INFO: Using a generated random seed 5616061
[12/15 16:43:05] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:43:05] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:43:06] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:43:06] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:43:06] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:43:06] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:43:06] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:43:06] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:43:06] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/data/robotcar_mapper.py", line 94, in __call__
    lidar_history_data = np.fromfile(lidar_history_name, dtype=np.float32)
FileNotFoundError: [Errno 2] No such file or directory: './data/RobotCar/object/lidar_history/1547122861418411_1.bin'

[12/15 16:43:06] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:48:45] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:48:45] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:48:45] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:48:45] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:48:45] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:48:45] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:48:45] d2.utils.env INFO: Using a generated random seed 45494422
[12/15 16:48:45] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:48:45] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:48:46] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:48:46] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:48:46] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:48:46] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:48:46] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:48:46] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:48:46] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 38, in forward
    features = self.backbone(radar_data.tensor, lidar_data.tensor)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/backbone/mvdnet_backbone.py", line 196, in forward
    lidar_features = self.lidar_backbone(lidar_data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/backbone/mvdnet_backbone.py", line 145, in forward
    x_j = self.stem(x[:,j,:,:,:])
IndexError: index 1 is out of bounds for dimension 1 with size 1
[12/15 16:48:46] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:51:24] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:51:24] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:51:24] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:51:24] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:51:24] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:51:24] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:51:24] d2.utils.env INFO: Using a generated random seed 24922378
[12/15 16:51:25] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:51:25] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:51:25] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:51:25] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:51:25] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:51:25] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:51:25] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:51:25] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:51:26] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 38, in forward
    features = self.backbone(radar_data.tensor, lidar_data.tensor)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/backbone/mvdnet_backbone.py", line 199, in forward
    lidar_features = self.lidar_backbone(lidar_data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/backbone/mvdnet_backbone.py", line 147, in forward
    logging.info(f"Shape of input: {x[:,j,:,:,:].shape}")
IndexError: index 1 is out of bounds for dimension 1 with size 1
[12/15 16:51:26] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:52:10] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:52:10] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:52:10] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:52:10] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:52:10] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:52:10] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:52:10] d2.utils.env INFO: Using a generated random seed 10635586
[12/15 16:52:10] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:52:10] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:52:11] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:52:11] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:52:11] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:52:11] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:52:11] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:52:11] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:52:11] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 38, in forward
    features = self.backbone(radar_data.tensor, lidar_data.tensor)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/backbone/mvdnet_backbone.py", line 199, in forward
    lidar_features = self.lidar_backbone(lidar_data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/backbone/mvdnet_backbone.py", line 148, in forward
    x_j = self.stem(x[:,j,:,:,:])
IndexError: index 1 is out of bounds for dimension 1 with size 1
[12/15 16:52:11] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:52:47] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:52:47] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:52:47] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:52:47] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:52:47] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:52:47] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:52:47] d2.utils.env INFO: Using a generated random seed 47994410
[12/15 16:52:48] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:52:48] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:52:48] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:52:48] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:52:48] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:52:48] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:52:48] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:52:48] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:52:49] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 38, in forward
    features = self.backbone(radar_data.tensor, lidar_data.tensor)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/backbone/mvdnet_backbone.py", line 199, in forward
    lidar_features = self.lidar_backbone(lidar_data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/backbone/mvdnet_backbone.py", line 148, in forward
    x_j = self.stem(x[:,j,:,:,:])
IndexError: index 1 is out of bounds for dimension 1 with size 1
[12/15 16:52:49] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:57:10] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:57:10] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:57:10] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:57:10] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:57:10] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:57:10] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:57:10] d2.utils.env INFO: Using a generated random seed 10630832
[12/15 16:57:10] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:57:10] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:57:11] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:57:11] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:57:11] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:57:11] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:57:11] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:57:11] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:57:11] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 38, in forward
    features = self.backbone(radar_data.tensor, lidar_data.tensor)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/backbone/mvdnet_backbone.py", line 203, in forward
    features = {"radar_rpn":radar_features["rpn"],
TypeError: list indices must be integers or slices, not str
[12/15 16:57:11] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 16:59:01] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 16:59:01] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.18.1+cu121 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 16:59:01] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 16:59:01] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: False 
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 16:59:01] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: False
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 16:59:01] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 16:59:01] d2.utils.env INFO: Using a generated random seed 1549173
[12/15 16:59:01] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 16:59:01] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 16:59:01] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 16:59:01] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 16:59:02] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 16:59:02] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 16:59:02] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 16:59:02] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 16:59:02] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 41, in forward
    proposals, proposal_losses = self.proposal_generator(radar_data, features, gt_instances)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/proposal_generator/mvdnet_rrpn.py", line 180, in forward
    for loss_key, loss_val in outputs[f].losses().items():
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rpn_outputs.py", line 327, in losses
    gt_objectness_logits, gt_anchor_deltas = self._get_ground_truth()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rrpn_outputs.py", line 222, in _get_ground_truth
    match_quality_matrix = pairwise_iou_rotated(gt_boxes_i, anchors_i)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/structures/rotated_boxes.py", line 498, in pairwise_iou
    return pairwise_iou_rotated(boxes1.tensor, boxes2.tensor)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/layers/rotated_boxes.py", line 23, in pairwise_iou_rotated
    return _C.box_iou_rotated(boxes1, boxes2)
RuntimeError: Not compiled with GPU support
[12/15 16:59:02] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 18:08:19] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 18:08:21] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.4.1+cu124 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 None
Pillow                    9.0.1
torchvision               0.19.1+cu124 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 18:08:21] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 18:08:21] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: False 
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 18:08:21] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: False
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 18:08:21] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 18:08:21] d2.utils.env INFO: Using a generated random seed 21286425
[12/15 18:08:21] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 18:08:21] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 18:08:21] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 18:08:21] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 18:08:21] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 18:08:21] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 18:08:21] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 18:08:21] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 18:08:22] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 41, in forward
    proposals, proposal_losses = self.proposal_generator(radar_data, features, gt_instances)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/proposal_generator/mvdnet_rrpn.py", line 180, in forward
    for loss_key, loss_val in outputs[f].losses().items():
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rpn_outputs.py", line 327, in losses
    gt_objectness_logits, gt_anchor_deltas = self._get_ground_truth()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rrpn_outputs.py", line 222, in _get_ground_truth
    match_quality_matrix = pairwise_iou_rotated(gt_boxes_i, anchors_i)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/structures/rotated_boxes.py", line 498, in pairwise_iou
    return pairwise_iou_rotated(boxes1.tensor, boxes2.tensor)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/layers/rotated_boxes.py", line 23, in pairwise_iou_rotated
    return _C.box_iou_rotated(boxes1, boxes2)
RuntimeError: Not compiled with GPU support
[12/15 18:08:22] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 18:20:48] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 18:20:50] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.4.1+cu124 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 /usr
NVCC                      Build cuda_11.5.r11.5/compiler.30672275_0
Pillow                    9.0.1
torchvision               0.19.1+cu124 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    sm_50, sm_60, sm_70, sm_75, sm_80, sm_86, sm_90
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 18:20:50] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 18:20:50] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: False 
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 18:20:50] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: False
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 18:20:50] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 18:20:50] d2.utils.env INFO: Using a generated random seed 50196824
[12/15 18:20:50] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 18:20:50] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 18:20:50] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 18:20:50] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 18:20:50] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 18:20:50] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 18:20:50] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 18:20:50] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 18:20:51] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 41, in forward
    proposals, proposal_losses = self.proposal_generator(radar_data, features, gt_instances)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/proposal_generator/mvdnet_rrpn.py", line 180, in forward
    for loss_key, loss_val in outputs[f].losses().items():
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rpn_outputs.py", line 327, in losses
    gt_objectness_logits, gt_anchor_deltas = self._get_ground_truth()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rrpn_outputs.py", line 222, in _get_ground_truth
    match_quality_matrix = pairwise_iou_rotated(gt_boxes_i, anchors_i)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/structures/rotated_boxes.py", line 498, in pairwise_iou
    return pairwise_iou_rotated(boxes1.tensor, boxes2.tensor)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/layers/rotated_boxes.py", line 23, in pairwise_iou_rotated
    return _C.box_iou_rotated(boxes1, boxes2)
RuntimeError: Not compiled with GPU support
[12/15 18:20:51] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 18:52:12] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 18:52:14] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.4.1+cu124 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 /usr/local/cuda
NVCC                      Build cuda_12.4.r12.4/compiler.34097967_0
Pillow                    9.0.1
torchvision               0.19.1+cu124 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    sm_50, sm_60, sm_70, sm_75, sm_80, sm_86, sm_90
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 18:52:14] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 18:52:14] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: False 
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 18:52:14] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: False
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 18:52:14] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 18:52:14] d2.utils.env INFO: Using a generated random seed 14382681
[12/15 18:52:14] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 18:52:14] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 18:52:14] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 18:52:14] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 18:52:14] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 18:52:14] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 18:52:15] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 18:52:15] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 18:52:15] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 41, in forward
    proposals, proposal_losses = self.proposal_generator(radar_data, features, gt_instances)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/proposal_generator/mvdnet_rrpn.py", line 180, in forward
    for loss_key, loss_val in outputs[f].losses().items():
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rpn_outputs.py", line 327, in losses
    gt_objectness_logits, gt_anchor_deltas = self._get_ground_truth()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rrpn_outputs.py", line 222, in _get_ground_truth
    match_quality_matrix = pairwise_iou_rotated(gt_boxes_i, anchors_i)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/structures/rotated_boxes.py", line 498, in pairwise_iou
    return pairwise_iou_rotated(boxes1.tensor, boxes2.tensor)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/layers/rotated_boxes.py", line 23, in pairwise_iou_rotated
    return _C.box_iou_rotated(boxes1, boxes2)
RuntimeError: Not compiled with GPU support
[12/15 18:52:15] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 19:05:30] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 19:05:32] detectron2 INFO: Environment info:
------------------------  ----------------------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.4.1+cu124 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 /usr/local/cuda-12.4/bin
NVCC
Pillow                    9.0.1
torchvision               0.19.1+cu124 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    /home/cavalier/.local/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
cv2                       4.5.4
------------------------  ----------------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 19:05:32] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 19:05:32] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: False 
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 19:05:32] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: False
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 19:05:32] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 19:05:32] d2.utils.env INFO: Using a generated random seed 32140374
[12/15 19:05:32] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 19:05:33] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 19:05:33] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 19:05:33] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 19:05:33] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 19:05:33] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 19:05:33] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 19:05:33] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 19:05:34] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 41, in forward
    proposals, proposal_losses = self.proposal_generator(radar_data, features, gt_instances)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/proposal_generator/mvdnet_rrpn.py", line 180, in forward
    for loss_key, loss_val in outputs[f].losses().items():
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rpn_outputs.py", line 327, in losses
    gt_objectness_logits, gt_anchor_deltas = self._get_ground_truth()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rrpn_outputs.py", line 222, in _get_ground_truth
    match_quality_matrix = pairwise_iou_rotated(gt_boxes_i, anchors_i)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/structures/rotated_boxes.py", line 498, in pairwise_iou
    return pairwise_iou_rotated(boxes1.tensor, boxes2.tensor)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/layers/rotated_boxes.py", line 23, in pairwise_iou_rotated
    return _C.box_iou_rotated(boxes1, boxes2)
RuntimeError: Not compiled with GPU support
[12/15 19:05:34] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 19:06:56] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 19:06:58] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/cavalier/cs6501-wireless-project/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.4.1+cu124 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 /usr/local/cuda-12.4
NVCC                      Build cuda_12.4.r12.4/compiler.34097967_0
Pillow                    9.0.1
torchvision               0.19.1+cu124 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    sm_50, sm_60, sm_70, sm_75, sm_80, sm_86, sm_90
cv2                       4.5.4
------------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 19:06:58] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 19:06:58] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: False 
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 19:06:58] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: False
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 19:06:58] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 19:06:58] d2.utils.env INFO: Using a generated random seed 58474803
[12/15 19:06:58] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 19:06:58] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 19:06:58] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 19:06:58] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 19:06:59] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 19:06:59] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 19:06:59] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 19:06:59] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 19:06:59] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/meta_arch/mvdnet.py", line 41, in forward
    proposals, proposal_losses = self.proposal_generator(radar_data, features, gt_instances)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/cavalier/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/cavalier/cs6501-wireless-project/mvdnet/modeling/proposal_generator/mvdnet_rrpn.py", line 180, in forward
    for loss_key, loss_val in outputs[f].losses().items():
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rpn_outputs.py", line 327, in losses
    gt_objectness_logits, gt_anchor_deltas = self._get_ground_truth()
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/modeling/proposal_generator/rrpn_outputs.py", line 222, in _get_ground_truth
    match_quality_matrix = pairwise_iou_rotated(gt_boxes_i, anchors_i)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/structures/rotated_boxes.py", line 498, in pairwise_iou
    return pairwise_iou_rotated(boxes1.tensor, boxes2.tensor)
  File "/home/cavalier/cs6501-wireless-project/detectron2/detectron2/layers/rotated_boxes.py", line 23, in pairwise_iou_rotated
    return _C.box_iou_rotated(boxes1, boxes2)
RuntimeError: Not compiled with GPU support
[12/15 19:06:59] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[12/15 19:17:03] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 19:20:15] detectron2 INFO: Rank of current process: 0. World size: 1
[12/15 19:20:16] detectron2 INFO: Environment info:
------------------------  ----------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
numpy                     1.24.2
detectron2                0.1.1 @/home/cavalier/cs6501-wireless-project/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  12.4
detectron2 arch flags     sm_75
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.4.1+cu124 @/home/cavalier/.local/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA GeForce RTX 2080 Super with Max-Q Design
CUDA_HOME                 /usr/local/cuda-12.4
NVCC                      Build cuda_12.4.r12.4/compiler.34097967_0
Pillow                    9.0.1
torchvision               0.19.1+cu124 @/home/cavalier/.local/lib/python3.10/site-packages/torchvision
torchvision arch flags    sm_50, sm_60, sm_70, sm_75, sm_80, sm_86, sm_90
cv2                       4.5.4
------------------------  ----------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/15 19:20:16] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[12/15 19:20:16] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: False 
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/15 19:20:16] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: False
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/15 19:20:17] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/15 19:20:17] d2.utils.env INFO: Using a generated random seed 17034707
[12/15 19:20:17] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/15 19:20:17] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/15 19:20:17] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |[0m
[12/15 19:20:17] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/15 19:20:17] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/15 19:20:17] d2.data.build INFO: Using training sampler TrainingSampler
[12/15 19:20:17] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/15 19:20:17] d2.engine.train_loop INFO: Starting training from iteration 0
[12/15 19:20:25] d2.utils.events INFO:  eta: 11:32:54  iter: 19  total_loss: 2.887  loss_cls: 0.567  loss_box_reg: 0.053  loss_direct: 0.026  radar_rpn_loss_rpn_cls: 0.693  radar_rpn_loss_rpn_loc: 0.429  lidar_rpn_loss_rpn_cls: 0.694  lidar_rpn_loss_rpn_loc: 0.424  time: 0.3466  data_time: 0.0149  lr: 0.000200  max_mem: 1057M
[12/15 19:20:32] d2.utils.events INFO:  eta: 11:24:40  iter: 39  total_loss: 2.662  loss_cls: 0.264  loss_box_reg: 0.096  loss_direct: 0.033  radar_rpn_loss_rpn_cls: 0.692  radar_rpn_loss_rpn_loc: 0.419  lidar_rpn_loss_rpn_cls: 0.692  lidar_rpn_loss_rpn_loc: 0.400  time: 0.3391  data_time: 0.0048  lr: 0.000400  max_mem: 1057M
[12/15 19:20:38] d2.utils.events INFO:  eta: 10:59:14  iter: 59  total_loss: 2.696  loss_cls: 0.283  loss_box_reg: 0.210  loss_direct: 0.048  radar_rpn_loss_rpn_cls: 0.690  radar_rpn_loss_rpn_loc: 0.421  lidar_rpn_loss_rpn_cls: 0.687  lidar_rpn_loss_rpn_loc: 0.358  time: 0.3287  data_time: 0.0050  lr: 0.000599  max_mem: 1057M
[12/15 19:20:44] d2.utils.events INFO:  eta: 10:24:11  iter: 79  total_loss: 2.601  loss_cls: 0.223  loss_box_reg: 0.161  loss_direct: 0.040  radar_rpn_loss_rpn_cls: 0.688  radar_rpn_loss_rpn_loc: 0.402  lidar_rpn_loss_rpn_cls: 0.684  lidar_rpn_loss_rpn_loc: 0.301  time: 0.3235  data_time: 0.0048  lr: 0.000799  max_mem: 1057M
[12/15 19:20:50] d2.utils.events INFO:  eta: 10:20:00  iter: 99  total_loss: 2.449  loss_cls: 0.174  loss_box_reg: 0.103  loss_direct: 0.034  radar_rpn_loss_rpn_cls: 0.685  radar_rpn_loss_rpn_loc: 0.343  lidar_rpn_loss_rpn_cls: 0.669  lidar_rpn_loss_rpn_loc: 0.300  time: 0.3205  data_time: 0.0047  lr: 0.000999  max_mem: 1057M
[12/15 19:20:56] d2.utils.events INFO:  eta: 10:19:53  iter: 119  total_loss: 2.337  loss_cls: 0.206  loss_box_reg: 0.151  loss_direct: 0.039  radar_rpn_loss_rpn_cls: 0.675  radar_rpn_loss_rpn_loc: 0.255  lidar_rpn_loss_rpn_cls: 0.645  lidar_rpn_loss_rpn_loc: 0.242  time: 0.3186  data_time: 0.0051  lr: 0.001199  max_mem: 1057M
[12/15 19:21:03] d2.utils.events INFO:  eta: 10:20:29  iter: 139  total_loss: 1.990  loss_cls: 0.131  loss_box_reg: 0.057  loss_direct: 0.020  radar_rpn_loss_rpn_cls: 0.669  radar_rpn_loss_rpn_loc: 0.239  lidar_rpn_loss_rpn_cls: 0.639  lidar_rpn_loss_rpn_loc: 0.235  time: 0.3176  data_time: 0.0048  lr: 0.001399  max_mem: 1057M
[12/15 19:21:09] d2.utils.events INFO:  eta: 10:21:28  iter: 159  total_loss: 2.246  loss_cls: 0.220  loss_box_reg: 0.160  loss_direct: 0.038  radar_rpn_loss_rpn_cls: 0.645  radar_rpn_loss_rpn_loc: 0.246  lidar_rpn_loss_rpn_cls: 0.605  lidar_rpn_loss_rpn_loc: 0.244  time: 0.3169  data_time: 0.0049  lr: 0.001598  max_mem: 1057M
[12/15 19:21:15] d2.utils.events INFO:  eta: 10:21:57  iter: 179  total_loss: 2.032  loss_cls: 0.190  loss_box_reg: 0.108  loss_direct: 0.030  radar_rpn_loss_rpn_cls: 0.628  radar_rpn_loss_rpn_loc: 0.261  lidar_rpn_loss_rpn_cls: 0.585  lidar_rpn_loss_rpn_loc: 0.282  time: 0.3164  data_time: 0.0049  lr: 0.001798  max_mem: 1057M
[12/15 19:21:21] d2.utils.events INFO:  eta: 10:22:40  iter: 199  total_loss: 2.240  loss_cls: 0.195  loss_box_reg: 0.119  loss_direct: 0.040  radar_rpn_loss_rpn_cls: 0.652  radar_rpn_loss_rpn_loc: 0.276  lidar_rpn_loss_rpn_cls: 0.625  lidar_rpn_loss_rpn_loc: 0.289  time: 0.3160  data_time: 0.0048  lr: 0.001998  max_mem: 1057M
[12/15 19:21:28] d2.utils.events INFO:  eta: 10:23:08  iter: 219  total_loss: 2.117  loss_cls: 0.215  loss_box_reg: 0.169  loss_direct: 0.049  radar_rpn_loss_rpn_cls: 0.567  radar_rpn_loss_rpn_loc: 0.203  lidar_rpn_loss_rpn_cls: 0.538  lidar_rpn_loss_rpn_loc: 0.244  time: 0.3158  data_time: 0.0049  lr: 0.002198  max_mem: 1057M
[12/15 19:21:34] d2.utils.events INFO:  eta: 10:23:59  iter: 239  total_loss: 1.982  loss_cls: 0.141  loss_box_reg: 0.090  loss_direct: 0.030  radar_rpn_loss_rpn_cls: 0.595  radar_rpn_loss_rpn_loc: 0.206  lidar_rpn_loss_rpn_cls: 0.591  lidar_rpn_loss_rpn_loc: 0.229  time: 0.3157  data_time: 0.0048  lr: 0.002398  max_mem: 1057M
[12/15 19:21:40] d2.utils.events INFO:  eta: 10:24:23  iter: 259  total_loss: 2.169  loss_cls: 0.280  loss_box_reg: 0.216  loss_direct: 0.067  radar_rpn_loss_rpn_cls: 0.573  radar_rpn_loss_rpn_loc: 0.265  lidar_rpn_loss_rpn_cls: 0.560  lidar_rpn_loss_rpn_loc: 0.283  time: 0.3156  data_time: 0.0047  lr: 0.002597  max_mem: 1057M
[12/15 19:21:47] d2.utils.events INFO:  eta: 10:24:45  iter: 279  total_loss: 1.997  loss_cls: 0.157  loss_box_reg: 0.079  loss_direct: 0.033  radar_rpn_loss_rpn_cls: 0.572  radar_rpn_loss_rpn_loc: 0.191  lidar_rpn_loss_rpn_cls: 0.572  lidar_rpn_loss_rpn_loc: 0.195  time: 0.3156  data_time: 0.0048  lr: 0.002797  max_mem: 1057M
[12/15 19:21:53] d2.utils.events INFO:  eta: 10:25:21  iter: 299  total_loss: 1.863  loss_cls: 0.137  loss_box_reg: 0.110  loss_direct: 0.033  radar_rpn_loss_rpn_cls: 0.600  radar_rpn_loss_rpn_loc: 0.202  lidar_rpn_loss_rpn_cls: 0.575  lidar_rpn_loss_rpn_loc: 0.200  time: 0.3156  data_time: 0.0046  lr: 0.002997  max_mem: 1057M
[12/15 19:21:59] d2.utils.events INFO:  eta: 10:26:05  iter: 319  total_loss: 2.381  loss_cls: 0.200  loss_box_reg: 0.149  loss_direct: 0.035  radar_rpn_loss_rpn_cls: 0.584  radar_rpn_loss_rpn_loc: 0.215  lidar_rpn_loss_rpn_cls: 0.591  lidar_rpn_loss_rpn_loc: 0.211  time: 0.3156  data_time: 0.0047  lr: 0.003197  max_mem: 1057M
[12/15 19:22:06] d2.utils.events INFO:  eta: 10:26:25  iter: 339  total_loss: 2.192  loss_cls: 0.222  loss_box_reg: 0.151  loss_direct: 0.043  radar_rpn_loss_rpn_cls: 0.551  radar_rpn_loss_rpn_loc: 0.228  lidar_rpn_loss_rpn_cls: 0.559  lidar_rpn_loss_rpn_loc: 0.244  time: 0.3157  data_time: 0.0045  lr: 0.003397  max_mem: 1057M
[12/15 19:22:12] d2.utils.events INFO:  eta: 10:27:00  iter: 359  total_loss: 2.052  loss_cls: 0.232  loss_box_reg: 0.220  loss_direct: 0.056  radar_rpn_loss_rpn_cls: 0.508  radar_rpn_loss_rpn_loc: 0.232  lidar_rpn_loss_rpn_cls: 0.499  lidar_rpn_loss_rpn_loc: 0.229  time: 0.3157  data_time: 0.0046  lr: 0.003596  max_mem: 1057M
[12/15 19:22:18] d2.utils.events INFO:  eta: 10:27:46  iter: 379  total_loss: 2.220  loss_cls: 0.255  loss_box_reg: 0.264  loss_direct: 0.074  radar_rpn_loss_rpn_cls: 0.508  radar_rpn_loss_rpn_loc: 0.229  lidar_rpn_loss_rpn_cls: 0.492  lidar_rpn_loss_rpn_loc: 0.251  time: 0.3159  data_time: 0.0046  lr: 0.003796  max_mem: 1057M
[12/15 19:22:25] d2.utils.events INFO:  eta: 10:28:13  iter: 399  total_loss: 2.266  loss_cls: 0.239  loss_box_reg: 0.379  loss_direct: 0.082  radar_rpn_loss_rpn_cls: 0.487  radar_rpn_loss_rpn_loc: 0.224  lidar_rpn_loss_rpn_cls: 0.456  lidar_rpn_loss_rpn_loc: 0.244  time: 0.3160  data_time: 0.0046  lr: 0.003996  max_mem: 1057M
[12/15 19:22:31] d2.utils.events INFO:  eta: 10:28:46  iter: 419  total_loss: 1.923  loss_cls: 0.201  loss_box_reg: 0.234  loss_direct: 0.052  radar_rpn_loss_rpn_cls: 0.443  radar_rpn_loss_rpn_loc: 0.190  lidar_rpn_loss_rpn_cls: 0.415  lidar_rpn_loss_rpn_loc: 0.193  time: 0.3160  data_time: 0.0045  lr: 0.004196  max_mem: 1057M
[12/15 19:22:37] d2.utils.events INFO:  eta: 10:28:48  iter: 439  total_loss: 2.045  loss_cls: 0.229  loss_box_reg: 0.308  loss_direct: 0.066  radar_rpn_loss_rpn_cls: 0.457  radar_rpn_loss_rpn_loc: 0.239  lidar_rpn_loss_rpn_cls: 0.422  lidar_rpn_loss_rpn_loc: 0.242  time: 0.3161  data_time: 0.0046  lr: 0.004396  max_mem: 1057M
[12/15 19:22:44] d2.utils.events INFO:  eta: 10:29:07  iter: 459  total_loss: 2.109  loss_cls: 0.202  loss_box_reg: 0.179  loss_direct: 0.057  radar_rpn_loss_rpn_cls: 0.481  radar_rpn_loss_rpn_loc: 0.207  lidar_rpn_loss_rpn_cls: 0.418  lidar_rpn_loss_rpn_loc: 0.219  time: 0.3161  data_time: 0.0046  lr: 0.004595  max_mem: 1057M
[12/15 19:22:50] d2.utils.events INFO:  eta: 10:29:07  iter: 479  total_loss: 1.936  loss_cls: 0.190  loss_box_reg: 0.290  loss_direct: 0.065  radar_rpn_loss_rpn_cls: 0.444  radar_rpn_loss_rpn_loc: 0.186  lidar_rpn_loss_rpn_cls: 0.433  lidar_rpn_loss_rpn_loc: 0.204  time: 0.3162  data_time: 0.0046  lr: 0.004795  max_mem: 1057M
[12/15 19:22:57] d2.utils.events INFO:  eta: 10:29:13  iter: 499  total_loss: 2.017  loss_cls: 0.221  loss_box_reg: 0.315  loss_direct: 0.087  radar_rpn_loss_rpn_cls: 0.407  radar_rpn_loss_rpn_loc: 0.234  lidar_rpn_loss_rpn_cls: 0.362  lidar_rpn_loss_rpn_loc: 0.242  time: 0.3162  data_time: 0.0046  lr: 0.004995  max_mem: 1057M
[12/15 19:23:03] d2.utils.events INFO:  eta: 10:29:14  iter: 519  total_loss: 1.717  loss_cls: 0.180  loss_box_reg: 0.209  loss_direct: 0.057  radar_rpn_loss_rpn_cls: 0.376  radar_rpn_loss_rpn_loc: 0.236  lidar_rpn_loss_rpn_cls: 0.348  lidar_rpn_loss_rpn_loc: 0.240  time: 0.3162  data_time: 0.0046  lr: 0.005195  max_mem: 1057M
[12/15 19:23:09] d2.utils.events INFO:  eta: 10:29:23  iter: 539  total_loss: 2.203  loss_cls: 0.192  loss_box_reg: 0.359  loss_direct: 0.082  radar_rpn_loss_rpn_cls: 0.394  radar_rpn_loss_rpn_loc: 0.243  lidar_rpn_loss_rpn_cls: 0.359  lidar_rpn_loss_rpn_loc: 0.258  time: 0.3162  data_time: 0.0045  lr: 0.005395  max_mem: 1057M
[12/15 19:23:16] d2.utils.events INFO:  eta: 10:29:30  iter: 559  total_loss: 1.937  loss_cls: 0.225  loss_box_reg: 0.364  loss_direct: 0.078  radar_rpn_loss_rpn_cls: 0.392  radar_rpn_loss_rpn_loc: 0.229  lidar_rpn_loss_rpn_cls: 0.365  lidar_rpn_loss_rpn_loc: 0.235  time: 0.3163  data_time: 0.0045  lr: 0.005594  max_mem: 1057M
[12/15 19:23:22] d2.utils.events INFO:  eta: 10:29:35  iter: 579  total_loss: 2.009  loss_cls: 0.195  loss_box_reg: 0.323  loss_direct: 0.076  radar_rpn_loss_rpn_cls: 0.382  radar_rpn_loss_rpn_loc: 0.220  lidar_rpn_loss_rpn_cls: 0.333  lidar_rpn_loss_rpn_loc: 0.248  time: 0.3163  data_time: 0.0046  lr: 0.005794  max_mem: 1057M
[12/15 19:23:28] d2.utils.events INFO:  eta: 10:29:30  iter: 599  total_loss: 1.664  loss_cls: 0.128  loss_box_reg: 0.171  loss_direct: 0.031  radar_rpn_loss_rpn_cls: 0.371  radar_rpn_loss_rpn_loc: 0.204  lidar_rpn_loss_rpn_cls: 0.329  lidar_rpn_loss_rpn_loc: 0.245  time: 0.3163  data_time: 0.0047  lr: 0.005994  max_mem: 1057M
[12/15 19:23:35] d2.utils.events INFO:  eta: 10:29:32  iter: 619  total_loss: 1.760  loss_cls: 0.181  loss_box_reg: 0.334  loss_direct: 0.048  radar_rpn_loss_rpn_cls: 0.316  radar_rpn_loss_rpn_loc: 0.216  lidar_rpn_loss_rpn_cls: 0.366  lidar_rpn_loss_rpn_loc: 0.226  time: 0.3164  data_time: 0.0049  lr: 0.006194  max_mem: 1057M
[12/15 19:23:41] d2.utils.events INFO:  eta: 10:29:45  iter: 639  total_loss: 1.893  loss_cls: 0.165  loss_box_reg: 0.282  loss_direct: 0.069  radar_rpn_loss_rpn_cls: 0.331  radar_rpn_loss_rpn_loc: 0.238  lidar_rpn_loss_rpn_cls: 0.336  lidar_rpn_loss_rpn_loc: 0.238  time: 0.3165  data_time: 0.0047  lr: 0.006394  max_mem: 1057M
[12/15 19:23:48] d2.utils.events INFO:  eta: 10:30:05  iter: 659  total_loss: 1.840  loss_cls: 0.196  loss_box_reg: 0.305  loss_direct: 0.079  radar_rpn_loss_rpn_cls: 0.317  radar_rpn_loss_rpn_loc: 0.210  lidar_rpn_loss_rpn_cls: 0.370  lidar_rpn_loss_rpn_loc: 0.232  time: 0.3166  data_time: 0.0046  lr: 0.006593  max_mem: 1057M
[12/15 19:23:54] d2.utils.events INFO:  eta: 10:30:10  iter: 679  total_loss: 1.759  loss_cls: 0.157  loss_box_reg: 0.237  loss_direct: 0.060  radar_rpn_loss_rpn_cls: 0.386  radar_rpn_loss_rpn_loc: 0.249  lidar_rpn_loss_rpn_cls: 0.370  lidar_rpn_loss_rpn_loc: 0.218  time: 0.3167  data_time: 0.0045  lr: 0.006793  max_mem: 1057M
[12/15 19:24:00] d2.utils.events INFO:  eta: 10:30:17  iter: 699  total_loss: 1.641  loss_cls: 0.152  loss_box_reg: 0.246  loss_direct: 0.074  radar_rpn_loss_rpn_cls: 0.313  radar_rpn_loss_rpn_loc: 0.182  lidar_rpn_loss_rpn_cls: 0.331  lidar_rpn_loss_rpn_loc: 0.201  time: 0.3167  data_time: 0.0046  lr: 0.006993  max_mem: 1057M
[12/15 19:24:07] d2.utils.events INFO:  eta: 10:30:19  iter: 719  total_loss: 1.637  loss_cls: 0.146  loss_box_reg: 0.304  loss_direct: 0.071  radar_rpn_loss_rpn_cls: 0.340  radar_rpn_loss_rpn_loc: 0.184  lidar_rpn_loss_rpn_cls: 0.372  lidar_rpn_loss_rpn_loc: 0.211  time: 0.3168  data_time: 0.0045  lr: 0.007193  max_mem: 1057M
[12/15 19:24:13] d2.utils.events INFO:  eta: 10:30:29  iter: 739  total_loss: 1.607  loss_cls: 0.169  loss_box_reg: 0.309  loss_direct: 0.074  radar_rpn_loss_rpn_cls: 0.297  radar_rpn_loss_rpn_loc: 0.186  lidar_rpn_loss_rpn_cls: 0.341  lidar_rpn_loss_rpn_loc: 0.220  time: 0.3168  data_time: 0.0048  lr: 0.007393  max_mem: 1057M
[12/15 19:24:20] d2.utils.events INFO:  eta: 10:30:35  iter: 759  total_loss: 1.587  loss_cls: 0.145  loss_box_reg: 0.170  loss_direct: 0.058  radar_rpn_loss_rpn_cls: 0.318  radar_rpn_loss_rpn_loc: 0.218  lidar_rpn_loss_rpn_cls: 0.287  lidar_rpn_loss_rpn_loc: 0.203  time: 0.3170  data_time: 0.0053  lr: 0.007592  max_mem: 1057M
[12/15 19:24:26] d2.utils.events INFO:  eta: 10:30:39  iter: 779  total_loss: 1.683  loss_cls: 0.181  loss_box_reg: 0.288  loss_direct: 0.093  radar_rpn_loss_rpn_cls: 0.267  radar_rpn_loss_rpn_loc: 0.220  lidar_rpn_loss_rpn_cls: 0.308  lidar_rpn_loss_rpn_loc: 0.240  time: 0.3170  data_time: 0.0049  lr: 0.007792  max_mem: 1057M
[12/15 19:24:32] d2.utils.events INFO:  eta: 10:30:48  iter: 799  total_loss: 1.592  loss_cls: 0.137  loss_box_reg: 0.181  loss_direct: 0.052  radar_rpn_loss_rpn_cls: 0.296  radar_rpn_loss_rpn_loc: 0.210  lidar_rpn_loss_rpn_cls: 0.276  lidar_rpn_loss_rpn_loc: 0.258  time: 0.3171  data_time: 0.0055  lr: 0.007992  max_mem: 1057M
[12/15 19:24:39] d2.utils.events INFO:  eta: 10:30:52  iter: 819  total_loss: 1.544  loss_cls: 0.159  loss_box_reg: 0.245  loss_direct: 0.061  radar_rpn_loss_rpn_cls: 0.256  radar_rpn_loss_rpn_loc: 0.217  lidar_rpn_loss_rpn_cls: 0.305  lidar_rpn_loss_rpn_loc: 0.203  time: 0.3172  data_time: 0.0048  lr: 0.008192  max_mem: 1057M
[12/15 19:24:45] d2.utils.events INFO:  eta: 10:30:56  iter: 839  total_loss: 1.621  loss_cls: 0.146  loss_box_reg: 0.227  loss_direct: 0.065  radar_rpn_loss_rpn_cls: 0.254  radar_rpn_loss_rpn_loc: 0.215  lidar_rpn_loss_rpn_cls: 0.359  lidar_rpn_loss_rpn_loc: 0.226  time: 0.3173  data_time: 0.0048  lr: 0.008392  max_mem: 1057M
[12/15 19:24:52] d2.utils.events INFO:  eta: 10:30:58  iter: 859  total_loss: 1.828  loss_cls: 0.167  loss_box_reg: 0.259  loss_direct: 0.065  radar_rpn_loss_rpn_cls: 0.375  radar_rpn_loss_rpn_loc: 0.229  lidar_rpn_loss_rpn_cls: 0.331  lidar_rpn_loss_rpn_loc: 0.216  time: 0.3174  data_time: 0.0049  lr: 0.008591  max_mem: 1057M
[12/15 19:24:58] d2.utils.events INFO:  eta: 10:30:59  iter: 879  total_loss: 1.619  loss_cls: 0.202  loss_box_reg: 0.225  loss_direct: 0.082  radar_rpn_loss_rpn_cls: 0.323  radar_rpn_loss_rpn_loc: 0.214  lidar_rpn_loss_rpn_cls: 0.344  lidar_rpn_loss_rpn_loc: 0.207  time: 0.3175  data_time: 0.0049  lr: 0.008791  max_mem: 1057M
[12/15 19:25:05] d2.utils.events INFO:  eta: 10:31:01  iter: 899  total_loss: 1.504  loss_cls: 0.135  loss_box_reg: 0.203  loss_direct: 0.057  radar_rpn_loss_rpn_cls: 0.318  radar_rpn_loss_rpn_loc: 0.197  lidar_rpn_loss_rpn_cls: 0.327  lidar_rpn_loss_rpn_loc: 0.204  time: 0.3177  data_time: 0.0051  lr: 0.008991  max_mem: 1057M
[12/15 19:25:11] d2.utils.events INFO:  eta: 10:31:07  iter: 919  total_loss: 1.962  loss_cls: 0.137  loss_box_reg: 0.145  loss_direct: 0.055  radar_rpn_loss_rpn_cls: 0.340  radar_rpn_loss_rpn_loc: 0.220  lidar_rpn_loss_rpn_cls: 0.472  lidar_rpn_loss_rpn_loc: 0.251  time: 0.3177  data_time: 0.0048  lr: 0.009191  max_mem: 1057M
[12/15 19:25:18] d2.utils.events INFO:  eta: 10:31:08  iter: 939  total_loss: 1.627  loss_cls: 0.153  loss_box_reg: 0.275  loss_direct: 0.076  radar_rpn_loss_rpn_cls: 0.290  radar_rpn_loss_rpn_loc: 0.189  lidar_rpn_loss_rpn_cls: 0.332  lidar_rpn_loss_rpn_loc: 0.242  time: 0.3178  data_time: 0.0048  lr: 0.009391  max_mem: 1057M
[12/15 19:25:24] d2.utils.events INFO:  eta: 10:31:11  iter: 959  total_loss: 1.561  loss_cls: 0.125  loss_box_reg: 0.281  loss_direct: 0.066  radar_rpn_loss_rpn_cls: 0.277  radar_rpn_loss_rpn_loc: 0.198  lidar_rpn_loss_rpn_cls: 0.322  lidar_rpn_loss_rpn_loc: 0.224  time: 0.3179  data_time: 0.0050  lr: 0.009590  max_mem: 1057M
[12/15 19:25:31] d2.utils.events INFO:  eta: 10:31:12  iter: 979  total_loss: 1.828  loss_cls: 0.136  loss_box_reg: 0.242  loss_direct: 0.043  radar_rpn_loss_rpn_cls: 0.390  radar_rpn_loss_rpn_loc: 0.252  lidar_rpn_loss_rpn_cls: 0.395  lidar_rpn_loss_rpn_loc: 0.277  time: 0.3180  data_time: 0.0050  lr: 0.009790  max_mem: 1057M
[12/15 19:25:37] d2.utils.events INFO:  eta: 10:31:14  iter: 999  total_loss: 1.705  loss_cls: 0.153  loss_box_reg: 0.326  loss_direct: 0.075  radar_rpn_loss_rpn_cls: 0.245  radar_rpn_loss_rpn_loc: 0.205  lidar_rpn_loss_rpn_cls: 0.298  lidar_rpn_loss_rpn_loc: 0.238  time: 0.3180  data_time: 0.0047  lr: 0.009990  max_mem: 1057M
[12/15 19:25:44] d2.utils.events INFO:  eta: 10:31:07  iter: 1019  total_loss: 1.765  loss_cls: 0.134  loss_box_reg: 0.144  loss_direct: 0.032  radar_rpn_loss_rpn_cls: 0.299  radar_rpn_loss_rpn_loc: 0.233  lidar_rpn_loss_rpn_cls: 0.390  lidar_rpn_loss_rpn_loc: 0.250  time: 0.3181  data_time: 0.0050  lr: 0.010000  max_mem: 1057M
[12/15 19:25:50] d2.utils.events INFO:  eta: 10:31:07  iter: 1039  total_loss: 1.782  loss_cls: 0.170  loss_box_reg: 0.190  loss_direct: 0.053  radar_rpn_loss_rpn_cls: 0.334  radar_rpn_loss_rpn_loc: 0.239  lidar_rpn_loss_rpn_cls: 0.359  lidar_rpn_loss_rpn_loc: 0.261  time: 0.3182  data_time: 0.0046  lr: 0.010000  max_mem: 1057M
[12/15 19:25:56] d2.utils.events INFO:  eta: 10:31:27  iter: 1059  total_loss: 1.881  loss_cls: 0.178  loss_box_reg: 0.244  loss_direct: 0.048  radar_rpn_loss_rpn_cls: 0.358  radar_rpn_loss_rpn_loc: 0.261  lidar_rpn_loss_rpn_cls: 0.382  lidar_rpn_loss_rpn_loc: 0.273  time: 0.3183  data_time: 0.0046  lr: 0.010000  max_mem: 1057M
[12/15 19:26:03] d2.utils.events INFO:  eta: 10:31:44  iter: 1079  total_loss: 1.872  loss_cls: 0.186  loss_box_reg: 0.268  loss_direct: 0.061  radar_rpn_loss_rpn_cls: 0.302  radar_rpn_loss_rpn_loc: 0.262  lidar_rpn_loss_rpn_cls: 0.372  lidar_rpn_loss_rpn_loc: 0.260  time: 0.3184  data_time: 0.0047  lr: 0.010000  max_mem: 1057M
[12/15 19:26:09] d2.utils.events INFO:  eta: 10:32:05  iter: 1099  total_loss: 1.691  loss_cls: 0.130  loss_box_reg: 0.252  loss_direct: 0.037  radar_rpn_loss_rpn_cls: 0.291  radar_rpn_loss_rpn_loc: 0.250  lidar_rpn_loss_rpn_cls: 0.356  lidar_rpn_loss_rpn_loc: 0.256  time: 0.3185  data_time: 0.0051  lr: 0.010000  max_mem: 1057M
[12/15 19:26:16] d2.utils.events INFO:  eta: 10:32:22  iter: 1119  total_loss: 1.729  loss_cls: 0.134  loss_box_reg: 0.236  loss_direct: 0.049  radar_rpn_loss_rpn_cls: 0.331  radar_rpn_loss_rpn_loc: 0.204  lidar_rpn_loss_rpn_cls: 0.376  lidar_rpn_loss_rpn_loc: 0.234  time: 0.3185  data_time: 0.0050  lr: 0.010000  max_mem: 1057M
[12/15 19:26:22] d2.utils.events INFO:  eta: 10:32:49  iter: 1139  total_loss: 1.778  loss_cls: 0.157  loss_box_reg: 0.224  loss_direct: 0.060  radar_rpn_loss_rpn_cls: 0.283  radar_rpn_loss_rpn_loc: 0.221  lidar_rpn_loss_rpn_cls: 0.392  lidar_rpn_loss_rpn_loc: 0.243  time: 0.3186  data_time: 0.0047  lr: 0.010000  max_mem: 1057M
[12/15 19:26:29] d2.utils.events INFO:  eta: 10:33:07  iter: 1159  total_loss: 1.604  loss_cls: 0.140  loss_box_reg: 0.206  loss_direct: 0.058  radar_rpn_loss_rpn_cls: 0.340  radar_rpn_loss_rpn_loc: 0.215  lidar_rpn_loss_rpn_cls: 0.333  lidar_rpn_loss_rpn_loc: 0.226  time: 0.3187  data_time: 0.0046  lr: 0.010000  max_mem: 1057M
[12/15 19:26:35] d2.utils.events INFO:  eta: 10:33:19  iter: 1179  total_loss: 1.436  loss_cls: 0.124  loss_box_reg: 0.202  loss_direct: 0.054  radar_rpn_loss_rpn_cls: 0.310  radar_rpn_loss_rpn_loc: 0.195  lidar_rpn_loss_rpn_cls: 0.281  lidar_rpn_loss_rpn_loc: 0.192  time: 0.3187  data_time: 0.0046  lr: 0.010000  max_mem: 1057M
[12/15 19:26:42] d2.utils.events INFO:  eta: 10:33:48  iter: 1199  total_loss: 1.288  loss_cls: 0.113  loss_box_reg: 0.147  loss_direct: 0.037  radar_rpn_loss_rpn_cls: 0.243  radar_rpn_loss_rpn_loc: 0.164  lidar_rpn_loss_rpn_cls: 0.284  lidar_rpn_loss_rpn_loc: 0.181  time: 0.3188  data_time: 0.0047  lr: 0.010000  max_mem: 1057M
[12/15 19:26:48] d2.utils.events INFO:  eta: 10:34:03  iter: 1219  total_loss: 1.715  loss_cls: 0.141  loss_box_reg: 0.217  loss_direct: 0.039  radar_rpn_loss_rpn_cls: 0.289  radar_rpn_loss_rpn_loc: 0.228  lidar_rpn_loss_rpn_cls: 0.361  lidar_rpn_loss_rpn_loc: 0.238  time: 0.3188  data_time: 0.0048  lr: 0.010000  max_mem: 1057M
[12/15 19:26:55] d2.utils.events INFO:  eta: 10:34:29  iter: 1239  total_loss: 1.795  loss_cls: 0.153  loss_box_reg: 0.257  loss_direct: 0.064  radar_rpn_loss_rpn_cls: 0.328  radar_rpn_loss_rpn_loc: 0.252  lidar_rpn_loss_rpn_cls: 0.397  lidar_rpn_loss_rpn_loc: 0.247  time: 0.3189  data_time: 0.0047  lr: 0.010000  max_mem: 1057M
[12/15 19:27:01] d2.utils.events INFO:  eta: 10:34:48  iter: 1259  total_loss: 1.503  loss_cls: 0.093  loss_box_reg: 0.155  loss_direct: 0.034  radar_rpn_loss_rpn_cls: 0.370  radar_rpn_loss_rpn_loc: 0.208  lidar_rpn_loss_rpn_cls: 0.339  lidar_rpn_loss_rpn_loc: 0.192  time: 0.3190  data_time: 0.0047  lr: 0.010000  max_mem: 1057M
[12/15 19:27:08] d2.utils.events INFO:  eta: 10:35:03  iter: 1279  total_loss: 1.468  loss_cls: 0.132  loss_box_reg: 0.254  loss_direct: 0.070  radar_rpn_loss_rpn_cls: 0.225  radar_rpn_loss_rpn_loc: 0.210  lidar_rpn_loss_rpn_cls: 0.256  lidar_rpn_loss_rpn_loc: 0.233  time: 0.3190  data_time: 0.0047  lr: 0.010000  max_mem: 1057M
[12/15 19:27:14] d2.utils.events INFO:  eta: 10:35:15  iter: 1299  total_loss: 1.332  loss_cls: 0.115  loss_box_reg: 0.287  loss_direct: 0.061  radar_rpn_loss_rpn_cls: 0.211  radar_rpn_loss_rpn_loc: 0.160  lidar_rpn_loss_rpn_cls: 0.213  lidar_rpn_loss_rpn_loc: 0.186  time: 0.3191  data_time: 0.0048  lr: 0.010000  max_mem: 1057M
[12/15 19:27:21] d2.utils.events INFO:  eta: 10:35:39  iter: 1319  total_loss: 1.481  loss_cls: 0.113  loss_box_reg: 0.118  loss_direct: 0.033  radar_rpn_loss_rpn_cls: 0.339  radar_rpn_loss_rpn_loc: 0.225  lidar_rpn_loss_rpn_cls: 0.390  lidar_rpn_loss_rpn_loc: 0.267  time: 0.3192  data_time: 0.0054  lr: 0.010000  max_mem: 1057M
[12/15 19:27:27] d2.utils.events INFO:  eta: 10:35:50  iter: 1339  total_loss: 1.313  loss_cls: 0.085  loss_box_reg: 0.179  loss_direct: 0.026  radar_rpn_loss_rpn_cls: 0.245  radar_rpn_loss_rpn_loc: 0.194  lidar_rpn_loss_rpn_cls: 0.310  lidar_rpn_loss_rpn_loc: 0.206  time: 0.3193  data_time: 0.0055  lr: 0.010000  max_mem: 1057M
[12/15 19:27:34] d2.utils.events INFO:  eta: 10:36:06  iter: 1359  total_loss: 1.774  loss_cls: 0.130  loss_box_reg: 0.231  loss_direct: 0.048  radar_rpn_loss_rpn_cls: 0.273  radar_rpn_loss_rpn_loc: 0.263  lidar_rpn_loss_rpn_cls: 0.393  lidar_rpn_loss_rpn_loc: 0.253  time: 0.3194  data_time: 0.0050  lr: 0.010000  max_mem: 1057M
[12/15 19:27:40] d2.utils.events INFO:  eta: 10:36:14  iter: 1379  total_loss: 1.550  loss_cls: 0.137  loss_box_reg: 0.237  loss_direct: 0.050  radar_rpn_loss_rpn_cls: 0.330  radar_rpn_loss_rpn_loc: 0.208  lidar_rpn_loss_rpn_cls: 0.366  lidar_rpn_loss_rpn_loc: 0.190  time: 0.3195  data_time: 0.0051  lr: 0.010000  max_mem: 1057M
[12/15 19:27:47] d2.utils.events INFO:  eta: 10:36:28  iter: 1399  total_loss: 1.413  loss_cls: 0.148  loss_box_reg: 0.237  loss_direct: 0.049  radar_rpn_loss_rpn_cls: 0.310  radar_rpn_loss_rpn_loc: 0.193  lidar_rpn_loss_rpn_cls: 0.260  lidar_rpn_loss_rpn_loc: 0.207  time: 0.3196  data_time: 0.0058  lr: 0.010000  max_mem: 1057M
[12/15 19:27:53] d2.utils.events INFO:  eta: 10:36:43  iter: 1419  total_loss: 1.677  loss_cls: 0.123  loss_box_reg: 0.174  loss_direct: 0.052  radar_rpn_loss_rpn_cls: 0.312  radar_rpn_loss_rpn_loc: 0.226  lidar_rpn_loss_rpn_cls: 0.350  lidar_rpn_loss_rpn_loc: 0.225  time: 0.3197  data_time: 0.0051  lr: 0.010000  max_mem: 1057M
[12/15 19:28:00] d2.utils.events INFO:  eta: 10:36:49  iter: 1439  total_loss: 1.594  loss_cls: 0.145  loss_box_reg: 0.317  loss_direct: 0.054  radar_rpn_loss_rpn_cls: 0.293  radar_rpn_loss_rpn_loc: 0.212  lidar_rpn_loss_rpn_cls: 0.343  lidar_rpn_loss_rpn_loc: 0.220  time: 0.3197  data_time: 0.0048  lr: 0.010000  max_mem: 1057M
[12/15 19:28:06] d2.utils.events INFO:  eta: 10:36:57  iter: 1459  total_loss: 1.590  loss_cls: 0.099  loss_box_reg: 0.163  loss_direct: 0.028  radar_rpn_loss_rpn_cls: 0.326  radar_rpn_loss_rpn_loc: 0.251  lidar_rpn_loss_rpn_cls: 0.315  lidar_rpn_loss_rpn_loc: 0.263  time: 0.3198  data_time: 0.0049  lr: 0.010000  max_mem: 1057M
[12/15 19:28:13] d2.utils.events INFO:  eta: 10:37:01  iter: 1479  total_loss: 1.572  loss_cls: 0.137  loss_box_reg: 0.259  loss_direct: 0.051  radar_rpn_loss_rpn_cls: 0.304  radar_rpn_loss_rpn_loc: 0.219  lidar_rpn_loss_rpn_cls: 0.271  lidar_rpn_loss_rpn_loc: 0.232  time: 0.3198  data_time: 0.0048  lr: 0.010000  max_mem: 1057M
[12/15 19:28:19] d2.utils.events INFO:  eta: 10:37:02  iter: 1499  total_loss: 1.577  loss_cls: 0.159  loss_box_reg: 0.316  loss_direct: 0.097  radar_rpn_loss_rpn_cls: 0.229  radar_rpn_loss_rpn_loc: 0.185  lidar_rpn_loss_rpn_cls: 0.293  lidar_rpn_loss_rpn_loc: 0.192  time: 0.3199  data_time: 0.0046  lr: 0.010000  max_mem: 1057M
[12/15 19:28:26] d2.utils.events INFO:  eta: 10:37:08  iter: 1519  total_loss: 1.571  loss_cls: 0.128  loss_box_reg: 0.226  loss_direct: 0.071  radar_rpn_loss_rpn_cls: 0.311  radar_rpn_loss_rpn_loc: 0.211  lidar_rpn_loss_rpn_cls: 0.311  lidar_rpn_loss_rpn_loc: 0.236  time: 0.3199  data_time: 0.0045  lr: 0.010000  max_mem: 1057M
[12/15 19:28:32] d2.utils.events INFO:  eta: 10:37:09  iter: 1539  total_loss: 1.264  loss_cls: 0.103  loss_box_reg: 0.194  loss_direct: 0.064  radar_rpn_loss_rpn_cls: 0.245  radar_rpn_loss_rpn_loc: 0.189  lidar_rpn_loss_rpn_cls: 0.242  lidar_rpn_loss_rpn_loc: 0.211  time: 0.3200  data_time: 0.0047  lr: 0.010000  max_mem: 1057M
[12/15 19:28:39] d2.utils.events INFO:  eta: 10:37:15  iter: 1559  total_loss: 1.538  loss_cls: 0.143  loss_box_reg: 0.203  loss_direct: 0.036  radar_rpn_loss_rpn_cls: 0.235  radar_rpn_loss_rpn_loc: 0.239  lidar_rpn_loss_rpn_cls: 0.412  lidar_rpn_loss_rpn_loc: 0.239  time: 0.3200  data_time: 0.0045  lr: 0.010000  max_mem: 1057M
[12/15 19:28:45] d2.utils.events INFO:  eta: 10:37:20  iter: 1579  total_loss: 1.557  loss_cls: 0.149  loss_box_reg: 0.229  loss_direct: 0.073  radar_rpn_loss_rpn_cls: 0.250  radar_rpn_loss_rpn_loc: 0.247  lidar_rpn_loss_rpn_cls: 0.293  lidar_rpn_loss_rpn_loc: 0.241  time: 0.3201  data_time: 0.0051  lr: 0.010000  max_mem: 1057M
[12/15 19:28:52] d2.utils.events INFO:  eta: 10:37:29  iter: 1599  total_loss: 1.613  loss_cls: 0.144  loss_box_reg: 0.231  loss_direct: 0.073  radar_rpn_loss_rpn_cls: 0.240  radar_rpn_loss_rpn_loc: 0.218  lidar_rpn_loss_rpn_cls: 0.347  lidar_rpn_loss_rpn_loc: 0.212  time: 0.3202  data_time: 0.0051  lr: 0.010000  max_mem: 1057M
[12/15 19:28:58] d2.utils.events INFO:  eta: 10:37:42  iter: 1619  total_loss: 1.423  loss_cls: 0.094  loss_box_reg: 0.173  loss_direct: 0.030  radar_rpn_loss_rpn_cls: 0.283  radar_rpn_loss_rpn_loc: 0.235  lidar_rpn_loss_rpn_cls: 0.264  lidar_rpn_loss_rpn_loc: 0.253  time: 0.3202  data_time: 0.0051  lr: 0.010000  max_mem: 1057M
[12/15 19:29:05] d2.utils.events INFO:  eta: 10:37:47  iter: 1639  total_loss: 1.448  loss_cls: 0.127  loss_box_reg: 0.186  loss_direct: 0.047  radar_rpn_loss_rpn_cls: 0.277  radar_rpn_loss_rpn_loc: 0.183  lidar_rpn_loss_rpn_cls: 0.328  lidar_rpn_loss_rpn_loc: 0.192  time: 0.3203  data_time: 0.0053  lr: 0.010000  max_mem: 1057M
[12/15 19:29:12] d2.utils.events INFO:  eta: 10:37:49  iter: 1659  total_loss: 1.528  loss_cls: 0.099  loss_box_reg: 0.207  loss_direct: 0.042  radar_rpn_loss_rpn_cls: 0.276  radar_rpn_loss_rpn_loc: 0.238  lidar_rpn_loss_rpn_cls: 0.354  lidar_rpn_loss_rpn_loc: 0.238  time: 0.3204  data_time: 0.0053  lr: 0.010000  max_mem: 1057M
[12/15 19:29:18] d2.utils.events INFO:  eta: 10:37:56  iter: 1679  total_loss: 1.617  loss_cls: 0.130  loss_box_reg: 0.284  loss_direct: 0.062  radar_rpn_loss_rpn_cls: 0.268  radar_rpn_loss_rpn_loc: 0.224  lidar_rpn_loss_rpn_cls: 0.347  lidar_rpn_loss_rpn_loc: 0.229  time: 0.3204  data_time: 0.0051  lr: 0.010000  max_mem: 1057M
[12/15 19:29:25] d2.utils.events INFO:  eta: 10:37:59  iter: 1699  total_loss: 1.492  loss_cls: 0.120  loss_box_reg: 0.210  loss_direct: 0.048  radar_rpn_loss_rpn_cls: 0.320  radar_rpn_loss_rpn_loc: 0.210  lidar_rpn_loss_rpn_cls: 0.340  lidar_rpn_loss_rpn_loc: 0.223  time: 0.3205  data_time: 0.0048  lr: 0.010000  max_mem: 1057M
[12/15 19:29:31] d2.utils.events INFO:  eta: 10:38:03  iter: 1719  total_loss: 1.404  loss_cls: 0.096  loss_box_reg: 0.222  loss_direct: 0.070  radar_rpn_loss_rpn_cls: 0.282  radar_rpn_loss_rpn_loc: 0.185  lidar_rpn_loss_rpn_cls: 0.313  lidar_rpn_loss_rpn_loc: 0.198  time: 0.3205  data_time: 0.0046  lr: 0.010000  max_mem: 1057M
[12/15 19:29:38] d2.utils.events INFO:  eta: 10:38:05  iter: 1739  total_loss: 1.253  loss_cls: 0.087  loss_box_reg: 0.157  loss_direct: 0.023  radar_rpn_loss_rpn_cls: 0.242  radar_rpn_loss_rpn_loc: 0.192  lidar_rpn_loss_rpn_cls: 0.247  lidar_rpn_loss_rpn_loc: 0.194  time: 0.3205  data_time: 0.0047  lr: 0.010000  max_mem: 1057M
[12/15 19:29:44] d2.utils.events INFO:  eta: 10:38:04  iter: 1759  total_loss: 1.521  loss_cls: 0.120  loss_box_reg: 0.239  loss_direct: 0.062  radar_rpn_loss_rpn_cls: 0.278  radar_rpn_loss_rpn_loc: 0.175  lidar_rpn_loss_rpn_cls: 0.247  lidar_rpn_loss_rpn_loc: 0.184  time: 0.3206  data_time: 0.0053  lr: 0.010000  max_mem: 1057M
[12/15 19:29:51] d2.utils.events INFO:  eta: 10:38:11  iter: 1779  total_loss: 1.591  loss_cls: 0.135  loss_box_reg: 0.237  loss_direct: 0.040  radar_rpn_loss_rpn_cls: 0.337  radar_rpn_loss_rpn_loc: 0.220  lidar_rpn_loss_rpn_cls: 0.326  lidar_rpn_loss_rpn_loc: 0.238  time: 0.3206  data_time: 0.0049  lr: 0.010000  max_mem: 1057M
[12/15 19:29:57] d2.utils.events INFO:  eta: 10:38:15  iter: 1799  total_loss: 1.527  loss_cls: 0.141  loss_box_reg: 0.323  loss_direct: 0.075  radar_rpn_loss_rpn_cls: 0.258  radar_rpn_loss_rpn_loc: 0.193  lidar_rpn_loss_rpn_cls: 0.329  lidar_rpn_loss_rpn_loc: 0.208  time: 0.3207  data_time: 0.0051  lr: 0.010000  max_mem: 1057M
[12/15 19:30:04] d2.utils.events INFO:  eta: 10:38:18  iter: 1819  total_loss: 1.323  loss_cls: 0.090  loss_box_reg: 0.183  loss_direct: 0.045  radar_rpn_loss_rpn_cls: 0.249  radar_rpn_loss_rpn_loc: 0.214  lidar_rpn_loss_rpn_cls: 0.235  lidar_rpn_loss_rpn_loc: 0.181  time: 0.3207  data_time: 0.0055  lr: 0.010000  max_mem: 1057M
[12/15 19:30:10] d2.utils.events INFO:  eta: 10:38:23  iter: 1839  total_loss: 1.307  loss_cls: 0.136  loss_box_reg: 0.189  loss_direct: 0.041  radar_rpn_loss_rpn_cls: 0.259  radar_rpn_loss_rpn_loc: 0.224  lidar_rpn_loss_rpn_cls: 0.263  lidar_rpn_loss_rpn_loc: 0.180  time: 0.3208  data_time: 0.0046  lr: 0.010000  max_mem: 1057M
[12/15 19:30:17] d2.utils.events INFO:  eta: 10:38:19  iter: 1859  total_loss: 1.448  loss_cls: 0.131  loss_box_reg: 0.183  loss_direct: 0.054  radar_rpn_loss_rpn_cls: 0.256  radar_rpn_loss_rpn_loc: 0.175  lidar_rpn_loss_rpn_cls: 0.274  lidar_rpn_loss_rpn_loc: 0.182  time: 0.3208  data_time: 0.0047  lr: 0.010000  max_mem: 1057M
[12/15 19:30:23] d2.utils.events INFO:  eta: 10:38:18  iter: 1879  total_loss: 1.278  loss_cls: 0.106  loss_box_reg: 0.230  loss_direct: 0.032  radar_rpn_loss_rpn_cls: 0.218  radar_rpn_loss_rpn_loc: 0.183  lidar_rpn_loss_rpn_cls: 0.253  lidar_rpn_loss_rpn_loc: 0.188  time: 0.3209  data_time: 0.0050  lr: 0.010000  max_mem: 1057M
[12/15 19:30:30] d2.utils.events INFO:  eta: 10:38:24  iter: 1899  total_loss: 1.698  loss_cls: 0.115  loss_box_reg: 0.259  loss_direct: 0.040  radar_rpn_loss_rpn_cls: 0.292  radar_rpn_loss_rpn_loc: 0.236  lidar_rpn_loss_rpn_cls: 0.368  lidar_rpn_loss_rpn_loc: 0.227  time: 0.3209  data_time: 0.0048  lr: 0.010000  max_mem: 1057M
[12/15 19:30:36] d2.utils.events INFO:  eta: 10:38:22  iter: 1919  total_loss: 1.307  loss_cls: 0.119  loss_box_reg: 0.205  loss_direct: 0.050  radar_rpn_loss_rpn_cls: 0.236  radar_rpn_loss_rpn_loc: 0.175  lidar_rpn_loss_rpn_cls: 0.249  lidar_rpn_loss_rpn_loc: 0.167  time: 0.3209  data_time: 0.0048  lr: 0.010000  max_mem: 1057M
[12/15 19:30:43] d2.utils.events INFO:  eta: 10:38:19  iter: 1939  total_loss: 1.268  loss_cls: 0.115  loss_box_reg: 0.206  loss_direct: 0.042  radar_rpn_loss_rpn_cls: 0.243  radar_rpn_loss_rpn_loc: 0.171  lidar_rpn_loss_rpn_cls: 0.284  lidar_rpn_loss_rpn_loc: 0.174  time: 0.3210  data_time: 0.0046  lr: 0.010000  max_mem: 1057M
[12/15 19:30:49] d2.utils.events INFO:  eta: 10:38:15  iter: 1959  total_loss: 1.256  loss_cls: 0.087  loss_box_reg: 0.168  loss_direct: 0.022  radar_rpn_loss_rpn_cls: 0.274  radar_rpn_loss_rpn_loc: 0.175  lidar_rpn_loss_rpn_cls: 0.295  lidar_rpn_loss_rpn_loc: 0.186  time: 0.3210  data_time: 0.0047  lr: 0.010000  max_mem: 1057M
[12/15 19:30:56] d2.utils.events INFO:  eta: 10:38:18  iter: 1979  total_loss: 1.491  loss_cls: 0.123  loss_box_reg: 0.197  loss_direct: 0.039  radar_rpn_loss_rpn_cls: 0.269  radar_rpn_loss_rpn_loc: 0.250  lidar_rpn_loss_rpn_cls: 0.266  lidar_rpn_loss_rpn_loc: 0.242  time: 0.3210  data_time: 0.0048  lr: 0.010000  max_mem: 1057M
[12/15 19:31:02] d2.utils.events INFO:  eta: 10:38:17  iter: 1999  total_loss: 1.353  loss_cls: 0.098  loss_box_reg: 0.208  loss_direct: 0.033  radar_rpn_loss_rpn_cls: 0.288  radar_rpn_loss_rpn_loc: 0.158  lidar_rpn_loss_rpn_cls: 0.309  lidar_rpn_loss_rpn_loc: 0.176  time: 0.3210  data_time: 0.0047  lr: 0.010000  max_mem: 1057M
