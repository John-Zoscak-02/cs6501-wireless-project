[11/02 12:45:10] detectron2 INFO: Rank of current process: 0. World size: 1
[11/02 12:45:11] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
cv2                       4.2.0
------------------------  -------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/02 12:45:11] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/02 12:45:11] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/02 12:45:11] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/02 12:45:11] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/02 12:45:11] d2.utils.env INFO: Using a generated random seed 12975389
[11/02 13:18:16] detectron2 INFO: Rank of current process: 0. World size: 1
[11/02 13:18:17] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/02 13:18:17] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/02 13:18:17] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/02 13:18:17] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/02 13:18:18] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/02 13:18:18] d2.utils.env INFO: Using a generated random seed 18477991
[11/02 13:28:02] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/02 13:28:04] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/02 13:28:04] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/02 13:28:04] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/02 13:28:04] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/02 13:28:04] d2.data.build INFO: Using training sampler TrainingSampler
[11/02 13:28:05] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/02 13:28:05] d2.engine.train_loop INFO: Starting training from iteration 0
[11/02 13:28:06] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 46, in __call__
    radar_intensity = utils.read_image(radar_intensity_name, format='L')
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/detection_utils.py", line 48, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 1062, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 653, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'data/RobotCar/object/radar/1547122315407487.jpg'

[11/02 13:28:06] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/03 08:19:00] detectron2 INFO: Rank of current process: 0. World size: 1
[11/03 08:19:02] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/03 08:19:02] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/03 08:19:02] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/03 08:19:02] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/03 08:19:02] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/03 08:19:02] d2.utils.env INFO: Using a generated random seed 3278491
[11/03 08:19:17] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/03 08:19:20] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/03 08:19:20] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/03 08:19:20] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/03 08:19:20] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/03 08:19:20] d2.data.build INFO: Using training sampler TrainingSampler
[11/03 08:19:21] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/03 08:19:21] d2.engine.train_loop INFO: Starting training from iteration 0
[11/03 08:19:21] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 46, in __call__
    radar_intensity = utils.read_image(radar_intensity_name, format='L')
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/detection_utils.py", line 48, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 1062, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 653, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'data/RobotCar/object/radar/1547122754400863.jpg'

[11/03 08:19:21] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/04 10:37:40] detectron2 INFO: Rank of current process: 0. World size: 1
[11/04 10:37:42] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
cv2                       4.2.0
------------------------  -------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/04 10:37:42] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/04 10:37:42] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/04 10:37:42] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/04 10:37:42] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/04 10:37:42] d2.utils.env INFO: Using a generated random seed 42588585
[11/04 10:40:06] detectron2 INFO: Rank of current process: 0. World size: 1
[11/04 10:40:07] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/04 10:40:07] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/04 10:40:07] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/04 10:40:07] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/04 10:40:07] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/04 10:40:07] d2.utils.env INFO: Using a generated random seed 8101875
[11/04 10:40:23] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/04 10:40:26] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/04 10:40:26] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/04 10:40:26] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/04 10:40:26] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/04 10:40:26] d2.data.build INFO: Using training sampler TrainingSampler
[11/04 10:40:27] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/04 10:40:27] d2.engine.train_loop INFO: Starting training from iteration 0
[11/04 10:40:27] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 46, in __call__
    radar_intensity = utils.read_image(radar_intensity_name, format='L')
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/detection_utils.py", line 48, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 1062, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 653, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'data/RobotCar/object/radar/1547120868675891.jpg'

[11/04 10:40:27] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/06 10:32:28] detectron2 INFO: Rank of current process: 0. World size: 1
[11/06 10:32:30] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
cv2                       4.2.0
------------------------  -------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/06 10:32:30] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/06 10:32:30] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/06 10:32:30] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/06 10:32:30] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/06 10:32:30] d2.utils.env INFO: Using a generated random seed 30892817
[11/06 10:34:41] detectron2 INFO: Rank of current process: 0. World size: 1
[11/06 10:34:42] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/06 10:34:42] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/06 10:34:42] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/06 10:34:42] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/06 10:34:42] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/06 10:34:42] d2.utils.env INFO: Using a generated random seed 43010158
[11/06 10:34:57] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/06 10:35:00] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/06 10:35:00] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/06 10:35:00] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/06 10:35:00] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/06 10:35:00] d2.data.build INFO: Using training sampler TrainingSampler
[11/06 10:35:01] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/06 10:35:01] d2.engine.train_loop INFO: Starting training from iteration 0
[11/06 10:35:01] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 46, in __call__
    radar_intensity = utils.read_image(radar_intensity_name, format='L')
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/detection_utils.py", line 48, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 1062, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 653, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'data/RobotCar/object/radar/1547120804903500.jpg'

[11/06 10:35:01] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/06 11:04:53] detectron2 INFO: Rank of current process: 0. World size: 1
[11/06 11:04:55] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/06 11:04:55] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/06 11:04:55] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/06 11:04:55] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/06 11:04:55] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/06 11:04:55] d2.utils.env INFO: Using a generated random seed 55807310
[11/06 11:05:10] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/06 11:05:13] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/06 11:05:14] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/06 11:05:14] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/06 11:05:14] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/06 11:05:14] d2.data.build INFO: Using training sampler TrainingSampler
[11/06 11:05:15] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/06 11:05:15] d2.engine.train_loop INFO: Starting training from iteration 0
[11/06 11:05:15] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 46, in __call__
    radar_intensity = utils.read_image(radar_intensity_name, format='L')
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/detection_utils.py", line 48, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 1062, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 653, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'data/RobotCar/object/radar/1547122807360707.jpg'

[11/06 11:05:15] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/06 16:39:15] detectron2 INFO: Rank of current process: 0. World size: 1
[11/06 16:39:17] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/06 16:39:17] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/06 16:39:17] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/06 16:39:17] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/06 16:39:17] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/06 16:39:17] d2.utils.env INFO: Using a generated random seed 18349016
[11/06 16:39:33] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/06 16:39:35] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/06 16:39:35] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/06 16:39:35] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/06 16:39:35] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/06 16:39:35] d2.data.build INFO: Using training sampler TrainingSampler
[11/06 16:39:36] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/06 16:39:36] d2.engine.train_loop INFO: Starting training from iteration 0
[11/06 16:39:37] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 46, in __call__
    radar_intensity = utils.read_image(radar_intensity_name, format='L')
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/detection_utils.py", line 48, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 1062, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 653, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'data/RobotCar/object/radar/1547122253664508.jpg'

[11/06 16:39:37] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/17 16:54:46] detectron2 INFO: Rank of current process: 0. World size: 1
[11/17 16:54:48] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/17 16:54:48] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/17 16:54:48] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/17 16:54:48] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/17 16:54:48] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/17 16:54:48] d2.utils.env INFO: Using a generated random seed 49307585
[11/17 16:55:03] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/17 16:55:06] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/17 16:55:06] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/17 16:55:06] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/17 16:55:06] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/17 16:55:06] d2.data.build INFO: Using training sampler TrainingSampler
[11/17 16:55:07] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/17 16:55:07] d2.engine.train_loop INFO: Starting training from iteration 0
[11/17 16:55:07] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 345, in __next__
    data = self._next_data()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 856, in _next_data
    return self._process_data(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 881, in _process_data
    data.reraise()
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/_utils.py", line 395, in reraise
    raise self.exc_type(msg)
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py", line 178, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 46, in __call__
    radar_intensity = utils.read_image(radar_intensity_name, format='L')
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/data/detection_utils.py", line 48, in read_image
    with PathManager.open(file_name, "rb") as f:
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 1062, in open
    bret = handler._open(path, mode, buffering=buffering, **kwargs)  # type: ignore
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/iopath/common/file_io.py", line 653, in _open
    opener=opener,
FileNotFoundError: [Errno 2] No such file or directory: 'data/RobotCar/object/radar/1547122462958457.jpg'

[11/17 16:55:07] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
[11/22 15:37:57] detectron2 INFO: Rank of current process: 0. World size: 1
[11/22 15:37:59] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/22 15:37:59] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/22 15:37:59] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/22 15:37:59] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/22 15:37:59] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/22 15:37:59] d2.utils.env INFO: Using a generated random seed 59730144
[11/22 15:38:13] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/22 15:38:15] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/22 15:38:16] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/22 15:38:16] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/22 15:38:16] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/22 15:38:16] d2.data.build INFO: Using training sampler TrainingSampler
[11/22 15:38:17] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/22 15:38:17] d2.engine.train_loop INFO: Starting training from iteration 0
[11/22 15:38:18] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 38, in forward
    features = self.backbone(radar_data.tensor, lidar_data.tensor)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 195, in forward
    radar_features = self.radar_backbone(radar_data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 148, in forward
    x_j = downsampler(x_j)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/layers/wrappers.py", line 95, in forward
    x = self.norm(x)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED
[11/22 15:38:18] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/22 15:45:26] detectron2 INFO: Rank of current process: 0. World size: 1
[11/22 15:45:27] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/22 15:45:27] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/22 15:45:27] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/22 15:45:27] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/22 15:45:27] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/22 15:45:27] d2.utils.env INFO: Using a generated random seed 27729343
[11/22 15:45:29] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/22 15:45:31] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/22 15:45:32] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/22 15:45:32] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/22 15:45:32] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/22 15:45:32] d2.data.build INFO: Using training sampler TrainingSampler
[11/22 15:45:32] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/22 15:45:32] d2.engine.train_loop INFO: Starting training from iteration 0
[11/22 15:45:33] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 38, in forward
    features = self.backbone(radar_data.tensor, lidar_data.tensor)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 195, in forward
    radar_features = self.radar_backbone(radar_data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 148, in forward
    x_j = downsampler(x_j)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/layers/wrappers.py", line 95, in forward
    x = self.norm(x)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED
[11/22 15:45:33] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/22 15:59:39] detectron2 INFO: Rank of current process: 0. World size: 1
[11/22 15:59:40] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
NVCC                      Build cuda_11.8.r11.8/compiler.31833905_0
Pillow                    9.5.0
torchvision               0.6.0 @/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.2.0
------------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/22 15:59:40] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/22 15:59:40] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/22 15:59:40] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/22 15:59:40] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/22 15:59:40] d2.utils.env INFO: Using a generated random seed 41362477
[11/22 15:59:54] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/22 15:59:57] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/22 15:59:57] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/22 15:59:57] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/22 15:59:57] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/22 15:59:57] d2.data.build INFO: Using training sampler TrainingSampler
[11/22 15:59:57] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/22 15:59:57] d2.engine.train_loop INFO: Starting training from iteration 0
[11/22 16:00:00] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 38, in forward
    features = self.backbone(radar_data.tensor, lidar_data.tensor)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 195, in forward
    radar_features = self.radar_backbone(radar_data)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 148, in forward
    x_j = downsampler(x_j)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/sfs/gpfs/tardis/home/jmz9sad/detectron2/detectron2/layers/wrappers.py", line 95, in forward
    x = self.norm(x)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/home/jmz9sad/.conda/envs/mvdnet/lib/python3.7/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED
[11/22 16:00:00] d2.engine.hooks INFO: Total training time: 0:00:02 (0:00:00 on hooks)
[11/24 02:21:03] detectron2 INFO: Rank of current process: 0. World size: 1
[11/24 02:21:03] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.7.7 (default, May  7 2020, 21:25:33) [GCC 7.3.0]
numpy                     1.18.1
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 7.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.1 @/opt/conda/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    7.1.2
torchvision               0.6.0a0+35d732a @/opt/conda/lib/python3.7/site-packages/torchvision
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/24 02:21:03] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/24 02:21:03] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/24 02:21:03] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/24 02:21:03] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/24 02:21:03] d2.utils.env INFO: Using a generated random seed 3819400
[11/25 15:41:30] detectron2 INFO: Rank of current process: 0. World size: 1
[11/25 15:41:30] detectron2 INFO: Environment info:
------------------------  -------------------------------------------------------------------
sys.platform              linux
Python                    3.7.7 (default, May  7 2020, 21:25:33) [GCC 7.3.0]
numpy                     1.18.1
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 7.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.1 @/opt/conda/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    7.1.2
torchvision               0.6.0a0+35d732a @/opt/conda/lib/python3.7/site-packages/torchvision
------------------------  -------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/25 15:41:30] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/25 15:41:30] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/25 15:41:30] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/25 15:41:30] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/25 15:41:30] d2.utils.env INFO: Using a generated random seed 31120380
[11/25 15:56:27] detectron2 INFO: Rank of current process: 0. World size: 1
[11/25 15:56:27] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.7 (default, May  7 2020, 21:25:33) [GCC 7.3.0]
numpy                     1.18.1
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 7.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/detectron2/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.5.1 @/opt/conda/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    7.1.2
torchvision               0.6.0a0+35d732a @/opt/conda/lib/python3.7/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.7/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[11/25 15:56:27] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/25 15:56:27] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/25 15:56:27] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/25 15:56:27] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/25 15:56:27] d2.utils.env INFO: Using a generated random seed 28400058
[11/25 16:10:02] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/25 16:10:06] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/25 16:10:06] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/25 16:10:06] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/25 16:10:06] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/25 16:10:06] d2.data.build INFO: Using training sampler TrainingSampler
[11/25 16:10:07] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/25 16:10:07] d2.engine.train_loop INFO: Starting training from iteration 0
[11/25 16:12:49] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/detectron2/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 38, in forward
    features = self.backbone(radar_data.tensor, lidar_data.tensor)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 195, in forward
    radar_features = self.radar_backbone(radar_data)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/backbone/mvdnet_backbone.py", line 148, in forward
    x_j = downsampler(x_j)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/detectron2/detectron2/layers/wrappers.py", line 95, in forward
    x = self.norm(x)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 106, in forward
    exponential_average_factor, self.eps)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py", line 1923, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED
[11/25 16:12:49] d2.engine.hooks INFO: Total training time: 0:02:41 (0:00:00 on hooks)
[11/26 17:24:35] detectron2 INFO: Rank of current process: 0. World size: 1
[11/26 17:24:36] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.7.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.2.0
torchvision               0.8.2 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torchvision
cv2                       4.6.0
------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.2-Product Build 20240823 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/26 17:24:36] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/26 17:24:36] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/26 17:24:36] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/26 17:24:36] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/26 17:24:36] d2.utils.env INFO: Using a generated random seed 37201137
[11/26 17:25:44] detectron2 INFO: Rank of current process: 0. World size: 1
[11/26 17:25:45] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.7.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/10.2.89
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    9.2.0
torchvision               0.8.2 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.6.0
------------------------  -----------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.2-Product Build 20240823 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/26 17:25:45] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/26 17:25:45] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/26 17:25:45] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/26 17:25:45] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/26 17:25:45] d2.utils.env INFO: Using a generated random seed 46056757
[11/26 17:25:54] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/26 17:25:57] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/26 17:25:57] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/26 17:25:57] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/26 17:25:57] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/26 17:25:57] d2.data.build INFO: Using training sampler TrainingSampler
[11/26 17:25:58] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/26 17:25:58] d2.engine.train_loop INFO: Starting training from iteration 0
[11/26 17:26:00] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 32, in forward
    radar_data, lidar_data = self.preprocess_image(batched_inputs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in preprocess_image
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in <listcomp>
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
RuntimeError: CUDA error: no kernel image is available for execution on the device
[11/26 17:26:00] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/26 17:56:24] detectron2 INFO: Rank of current process: 0. World size: 1
[11/26 17:56:26] detectron2 INFO: Environment info:
------------------------  --------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.7.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.2.0
torchvision               0.8.2 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torchvision
cv2                       4.6.0
------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.2-Product Build 20240823 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/26 17:56:26] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/26 17:56:26] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/26 17:56:26] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/26 17:56:26] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/26 17:56:26] d2.utils.env INFO: Using a generated random seed 26531846
[11/26 17:57:05] detectron2 INFO: Rank of current process: 0. World size: 1
[11/26 17:57:06] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.7.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/10.2.89
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    9.2.0
torchvision               0.8.2 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.6.0
------------------------  -----------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.2-Product Build 20240823 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/26 17:57:06] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/26 17:57:06] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/26 17:57:06] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/26 17:57:06] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/26 17:57:06] d2.utils.env INFO: Using a generated random seed 7571174
[11/26 17:57:15] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/26 17:57:17] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/26 17:57:18] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/26 17:57:18] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/26 17:57:18] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/26 17:57:18] d2.data.build INFO: Using training sampler TrainingSampler
[11/26 17:57:19] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/26 17:57:19] d2.engine.train_loop INFO: Starting training from iteration 0
[11/26 17:57:20] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 32, in forward
    radar_data, lidar_data = self.preprocess_image(batched_inputs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in preprocess_image
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in <listcomp>
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
RuntimeError: CUDA error: no kernel image is available for execution on the device
[11/26 17:57:20] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/26 18:02:50] detectron2 INFO: Rank of current process: 0. World size: 1
[11/26 18:02:51] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) [GCC 9.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2
detectron2 compiler       GCC 8.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.7.1 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/10.2.89
NVCC                      Cuda compilation tools, release 10.2, V10.2.89
Pillow                    9.2.0
torchvision               0.8.2 @/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torchvision
torchvision arch flags    sm_35, sm_50, sm_60, sm_70, sm_75
cv2                       4.6.0
------------------------  -----------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2024.2.2-Product Build 20240823 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/26 18:02:51] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/26 18:02:51] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/26 18:02:51] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/26 18:02:51] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/26 18:02:51] d2.utils.env INFO: Using a generated random seed 52022972
[11/26 18:02:51] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/26 18:02:53] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/26 18:02:54] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/26 18:02:54] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/26 18:02:54] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/26 18:02:54] d2.data.build INFO: Using training sampler TrainingSampler
[11/26 18:02:54] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/26 18:02:54] d2.engine.train_loop INFO: Starting training from iteration 0
[11/26 18:02:55] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/home/jmz9sad/.conda/envs/mvdnet2/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 32, in forward
    radar_data, lidar_data = self.preprocess_image(batched_inputs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in preprocess_image
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in <listcomp>
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
RuntimeError: CUDA error: no kernel image is available for execution on the device
[11/26 18:02:55] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/27 20:45:19] detectron2 INFO: Rank of current process: 0. World size: 1
[11/27 20:45:20] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.7.5 (default, Dec  9 2021, 17:04:37) [GCC 8.4.0]
numpy                     1.21.6
detectron2                0.1.1 @/usr/local/lib/python3.7/dist-packages/detectron2
detectron2 compiler       GCC 7.5
detectron2 CUDA compiler  not available
detectron2 arch flags     /usr/local/lib/python3.7/dist-packages/detectron2/_C.cpython-37m-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   1.7.1 @/usr/local/lib/python3.7/dist-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/10.2.89
Pillow                    9.5.0
torchvision               0.8.2 @/usr/local/lib/python3.7/dist-packages/torchvision
torchvision arch flags    /usr/local/lib/python3.7/dist-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  -----------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.2
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75
  - CuDNN 7.6.5
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[11/27 20:45:20] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', dist_url='tcp://127.0.0.1:55975', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[11/27 20:45:20] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/27 20:45:20] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/27 20:45:20] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/27 20:45:20] d2.utils.env INFO: Using a generated random seed 20735539
[11/27 20:45:29] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=[3, 3, 3], stride=(1, 1, 1), padding=[1, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=[5, 3, 3], stride=(1, 1, 1), padding=[0, 1, 1], bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[11/27 20:45:32] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[11/27 20:45:32] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[11/27 20:45:32] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[11/27 20:45:32] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[11/27 20:45:32] d2.data.build INFO: Using training sampler TrainingSampler
[11/27 20:45:33] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[11/27 20:45:33] d2.engine.train_loop INFO: Starting training from iteration 0
[11/27 20:45:35] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/usr/local/lib/python3.7/dist-packages/detectron2/engine/train_loop.py", line 215, in run_step
    loss_dict = self.model(data)
  File "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 32, in forward
    radar_data, lidar_data = self.preprocess_image(batched_inputs)
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in preprocess_image
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
  File "/home/jmz9sad/MVDNet/mvdnet/modeling/meta_arch/mvdnet.py", line 82, in <listcomp>
    radar_data = [torch.stack(x["radar_intensity"]).to(self.device).type(torch.float) for x in batched_inputs]
RuntimeError: CUDA error: no kernel image is available for execution on the device
[11/27 20:45:35] d2.engine.hooks INFO: Total training time: 0:00:01 (0:00:00 on hooks)
[11/28 15:33:08] detectron2 INFO: Rank of current process: 0. World size: 1
[11/28 15:33:09] detectron2 INFO: Environment info:
------------------------  ------------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/opt/conda/lib/python3.10/site-packages/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[11/28 15:33:09] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[11/28 15:33:09] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/28 15:33:09] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/28 15:33:09] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/28 15:33:09] d2.utils.env INFO: Using a generated random seed 10040964
[11/28 15:34:11] detectron2 INFO: Rank of current process: 0. World size: 1
[11/28 15:34:11] detectron2 INFO: Environment info:
------------------------  ------------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/opt/conda/lib/python3.10/site-packages/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[11/28 15:34:11] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[11/28 15:34:11] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/28 15:34:11] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/28 15:34:11] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/28 15:34:11] d2.utils.env INFO: Using a generated random seed 12101145
[11/28 15:35:33] detectron2 INFO: Rank of current process: 0. World size: 1
[11/28 15:35:33] detectron2 INFO: Environment info:
------------------------  ------------------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/opt/conda/lib/python3.10/site-packages/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /opt/conda/lib/python3.10/site-packages/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[11/28 15:35:33] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[11/28 15:35:33] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[11/28 15:35:33] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[11/28 15:35:33] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[11/28 15:35:33] d2.utils.env INFO: Using a generated random seed 34304592
[12/02 09:46:26] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 09:46:26] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
------------------------  -----------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 09:46:26] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 09:46:26] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 09:46:26] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 09:46:26] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 09:46:26] d2.utils.env INFO: Using a generated random seed 27237983
[12/02 09:58:22] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 09:58:22] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
------------------------  -----------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 09:58:22] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 09:58:22] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 09:58:22] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 09:58:22] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 09:58:22] d2.utils.env INFO: Using a generated random seed 23162567
[12/02 09:59:25] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 09:59:26] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
------------------------  -----------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 09:59:26] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 09:59:26] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 09:59:26] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 09:59:26] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 09:59:26] d2.utils.env INFO: Using a generated random seed 26252702
[12/02 10:01:05] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 10:01:05] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
------------------------  -----------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 10:01:05] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 10:01:05] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 10:01:05] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 10:01:05] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 10:01:05] d2.utils.env INFO: Using a generated random seed 6073420
[12/02 10:03:53] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 10:03:54] detectron2 INFO: Environment info:
------------------------  ---------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ---------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 10:03:54] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 10:03:54] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 10:03:54] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 10:03:54] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 10:03:54] d2.utils.env INFO: Using a generated random seed 54244387
[12/02 10:43:24] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 10:43:25] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/MVDNet/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
------------------------  -----------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 10:43:25] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 10:43:25] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 10:43:25] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 10:43:25] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 10:43:25] d2.utils.env INFO: Using a generated random seed 25514528
[12/02 11:57:22] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 11:57:23] detectron2 INFO: Environment info:
------------------------  -----------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/MVDNet/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            False
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
------------------------  -----------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 11:57:23] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 11:57:23] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 11:57:23] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 11:57:23] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 11:57:23] d2.utils.env INFO: Using a generated random seed 23515178
[12/02 12:22:08] detectron2 INFO: Rank of current process: 0. World size: 1
[12/02 12:22:09] detectron2 INFO: Environment info:
------------------------  ----------------------------------------------------------------------------------------------------
sys.platform              linux
Python                    3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]
numpy                     1.26.4
detectron2                0.1.1 @/home/jmz9sad/MVDNet/detectron2/detectron2
detectron2 compiler       GCC 11.4
detectron2 CUDA compiler  not available
detectron2 arch flags     /home/jmz9sad/MVDNet/detectron2/detectron2/_C.cpython-310-x86_64-linux-gnu.so; cannot find cuobjdump
DETECTRON2_ENV_MODULE     <not set>
PyTorch                   2.3.1 @/opt/conda/lib/python3.10/site-packages/torch
PyTorch debug build       False
CUDA available            True
GPU 0                     NVIDIA RTX A6000
CUDA_HOME                 /apps/software/standard/core/cuda/11.8.0
Pillow                    9.0.0
torchvision               0.18.1 @/opt/conda/lib/python3.10/site-packages/torchvision
torchvision arch flags    /opt/conda/lib/python3.10/site-packages/torchvision/_C.so; cannot find cuobjdump
------------------------  ----------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[12/02 12:22:09] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/train_config.yaml', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:55975', opts=[])
[12/02 12:22:09] detectron2 INFO: Contents of args.config_file=./configs/train_config.yaml:
INPUT:
  EVAL_BETA: 0.0
  HISTORY_ON: True
  NUM_HISTORY: 4
  LIDAR:
    FOG:
      G: 0.45
      N: 0.02
      D_MIN: 2
      FRACTION_RANDOM: 0.05
      FOG_RATIO: 0.5
      BETA_RANGE: [0.005, 0.08]
    PROJECTION:
      DELTA_L: 0.2
      PIXEL_L: 320
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      DELTA_H: 0.1
MODEL:
  META_ARCHITECTURE: "MVDNet"
  BACKBONE:
    NAME: build_mvdnet_backbone
  MVDNET:
    STEM_OUT_CHANNELS: 32
    STAGE_LAYERS: [3,3]
    RADAR_STAGE_OUT_CHANNELS: [32,64]
    LIDAR_STAGE_OUT_CHANNELS: [64,128]
    RADAR_NORM: "BN"
    LIDAR_NORM: "BN"
  ANCHOR_GENERATOR:
    NAME: RotatedAnchorGenerator
    ANGLES: [[-90, -45, 0, 45]]
    SIZES: [[26]] # Pixels
    ASPECT_RATIOS: [[2]]
  PROPOSAL_GENERATOR:
    NAME: MVDNetRRPN
    MIN_SIZE: 2
  RPN:
    BBOX_REG_WEIGHTS: (1,1,1,1,1)
    IN_FEATURES: ["radar_rpn", "lidar_rpn"]
    PRE_NMS_TOPK_TRAIN: 6000
    PRE_NMS_TOPK_TEST: 3000
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 500
    IOU_THRESHOLDS: [0.45, 0.55]
  ROI_HEADS:
    NAME: MVDNetROIHeads
    IN_FEATURES: ["radar_rcnn", "lidar_rcnn"]
    BATCH_SIZE_PER_IMAGE: 256
    NUM_CLASSES: 1
    NMS_THRESH_TEST: 0.2
    SCORE_THRESH_TEST: 0.1
  ROI_BOX_HEAD:
    NAME: MVDNetBoxHead
    POOLER_TYPE: ROIAlignRotated
    BBOX_REG_WEIGHTS: (10,10,5,5,1)
    NUM_FC: 2
    POOLER_RESOLUTION: 7
DATASETS:
  TRAIN: ("robotcar_train",)
  TEST: ("robotcar_eval",)
SOLVER:
  IMS_PER_BATCH: 1
  BASE_LR: 0.01
  MAX_ITER: 120000
  STEPS: (40000,80000)
  CHECKPOINT_PERIOD: 10000
OUTPUT_DIR: ./output/mvdnet/

[12/02 12:22:09] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('robotcar_eval',)
  TRAIN: ('robotcar_train',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  EVAL_BETA: 0.0
  FORMAT: BGR
  HISTORY_ON: True
  LIDAR:
    FOG:
      BETA_RANGE: [0.005, 0.08]
      D_MIN: 2
      FOG_RATIO: 0.5
      FRACTION_RANDOM: 0.05
      G: 0.45
      N: 0.02
    PROJECTION:
      DELTA_H: 0.1
      DELTA_L: 0.2
      HEIGHT_LB: -1.0
      HEIGHT_UB: 2.5
      PIXEL_L: 320
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  NUM_HISTORY: 4
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, -45, 0, 45]]
    ASPECT_RATIOS: [[2]]
    NAME: RotatedAnchorGenerator
    OFFSET: 0.0
    SIZES: [[26]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_mvdnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: MVDNet
  MVDNET:
    LIDAR_NORM: BN
    LIDAR_STAGE_OUT_CHANNELS: [64, 128]
    RADAR_NORM: BN
    RADAR_STAGE_OUT_CHANNELS: [32, 64]
    STAGE_LAYERS: [3, 3]
    STEM_OUT_CHANNELS: 32
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 2
    NAME: MVDNetRRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_WEIGHTS: (10, 10, 5, 5, 1)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: MVDNetBoxHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignRotated
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['radar_rcnn', 'lidar_rcnn']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: MVDNetROIHeads
    NMS_THRESH_TEST: 0.2
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.1
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_WEIGHTS: (1, 1, 1, 1, 1)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['radar_rpn', 'lidar_rpn']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.45, 0.55]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 500
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 3000
    PRE_NMS_TOPK_TRAIN: 6000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output/mvdnet/
SEED: -1
SOLVER:
  BASE_LR: 0.01
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 10000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 120000
  MOMENTUM: 0.9
  STEPS: (40000, 80000)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[12/02 12:22:09] detectron2 INFO: Full config saved to ./output/mvdnet/config.yaml
[12/02 12:22:09] d2.utils.env INFO: Using a generated random seed 9339795
[12/02 12:22:09] d2.engine.defaults INFO: Model:
MVDNet(
  (backbone): MVDNetBackbone(
    (radar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        160, 32, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (lidar_backbone): VGG(
      (stem): MVDNetStem(
        (conv1): Conv2d(
          36, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=32, eps=1e-05)
        )
      )
      (down1): Sequential(
        (0): Conv2d(
          32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (1): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (down2): Sequential(
        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (1): Conv2d(
          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (3): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (up1): ConvTranspose2d(
        128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fusion1): Conv2d(
        128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (final_fusion): Conv2d(
        320, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (proposal_generator): MVDNetRRPN(
    (radar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (lidar_rpn_anchor_generator): RotatedAnchorGenerator(
      (cell_anchors): BufferList()
    )
    (radar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(32, 20, kernel_size=(1, 1), stride=(1, 1))
    )
    (lidar_rpn_rpn_head): StandardRPNHead(
      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(64, 20, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (roi_heads): MVDNetROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlignRotated(output_size=(7, 7), spatial_scale=1.0, sampling_ratio=0)
      )
    )
    (box_head): MVDNetBoxHead(
      (match_conv): Conv2d(
        64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (radar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_self_attention): SelfAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (radar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (lidar_cross_attention): CrossAttentionBlock(
        (g): Linear(in_features=1568, out_features=196, bias=True)
        (theta): Linear(in_features=1568, out_features=196, bias=True)
        (phi): Linear(in_features=1568, out_features=196, bias=True)
        (W): Linear(in_features=196, out_features=1568, bias=True)
      )
      (tnn1): Conv3d(
        64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn2): Conv3d(
        32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (tnn3): Conv3d(
        32, 32, kernel_size=(5, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False
        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (fc1): Linear(in_features=1568, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=2, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=5, bias=True)
    )
    (direct_predictor): MVDNetRCNNOutputLayers(
      (direct_score): Linear(in_features=1024, out_features=2, bias=True)
    )
  )
)
[12/02 12:22:11] d2.data.build INFO: Removed 367 images with no usable annotations. 6697 images left.
[12/02 12:22:12] d2.data.build INFO: Distribution of instances among all 1 categories:
|  category  | #instances   |
|:----------:|:-------------|
|    car     | 42928        |
|            |              |
[12/02 12:22:12] d2.data.common INFO: Serializing 6697 elements to byte tensors and concatenating them all ...
[12/02 12:22:12] d2.data.common INFO: Serialized dataset takes 4.72 MiB
[12/02 12:22:12] d2.data.build INFO: Using training sampler TrainingSampler
[12/02 12:22:12] fvcore.common.checkpoint INFO: No checkpoint found. Initializing model from scratch
[12/02 12:22:12] d2.engine.train_loop INFO: Starting training from iteration 0
[12/02 12:22:13] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "/home/jmz9sad/MVDNet/detectron2/detectron2/engine/train_loop.py", line 132, in train
    self.run_step()
  File "/home/jmz9sad/MVDNet/detectron2/detectron2/engine/train_loop.py", line 209, in run_step
    data = next(self._data_loader_iter)
  File "/home/jmz9sad/MVDNet/detectron2/detectron2/data/common.py", line 140, in __iter__
    for d in self.dataset:
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/opt/conda/lib/python3.10/site-packages/torch/_utils.py", line 705, in reraise
    raise exception
AttributeError: Caught AttributeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/jmz9sad/MVDNet/detectron2/detectron2/data/common.py", line 41, in __getitem__
    data = self._map_func(self._dataset[cur_idx])
  File "/home/jmz9sad/MVDNet/detectron2/detectron2/utils/serialize.py", line 23, in __call__
    return self._obj(*args, **kwargs)
  File "/home/jmz9sad/MVDNet/mvdnet/data/robotcar_mapper.py", line 81, in __call__
    lidar_intensity, lidar_occupancy = lidar_pc2pixor(
  File "/home/jmz9sad/MVDNet/mvdnet/data/robotcar_utils.py", line 148, in lidar_pc2pixor
    pixel_h = np.int(np.round((h2 - h1) / delta_h))
  File "/opt/conda/lib/python3.10/site-packages/numpy/__init__.py", line 324, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'int'.
`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations

[12/02 12:22:13] d2.engine.hooks INFO: Total training time: 0:00:00 (0:00:00 on hooks)
